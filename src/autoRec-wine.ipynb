{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "nn_hdim = 4\n",
    "epsilon = 1e-4 # learning rate for gradient descent\n",
    "reg_lambda = 0.01\n",
    "size = \"100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(data_size):\n",
    "    ratings = []\n",
    "    if size == \"100k\":\n",
    "        path = os.path.join(\"Data\", \"ml-100k\", \"u.data\")\n",
    "        print(\"Read movie lens 100k data set\")\n",
    "        f = open(path, \"r\")\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            ratings.append(line.split()[0:-1])\n",
    "        f.close()\n",
    "    if size == \"1m\" or size == \"10m\":\n",
    "        path = os.path.join(\"Data\", \"ml-\" + size, \"ratings.dat\")\n",
    "        print(\"Read movie lens \" + size + \" data set\")\n",
    "        f = open(path, \"r\")\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            ratings.append(line.split(\"::\")[0:-1])\n",
    "        f.close()\n",
    "    if size == \"20m\":\n",
    "        path = os.path.join(\"Data\", \"ml-20m\", \"ratings.csv\")\n",
    "        print(\"Read movie lens 20m data set\")\n",
    "        f = open(path, \"r\")\n",
    "        line = f.readline()\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            ratings.append(line.split(\",\")[0:-1])\n",
    "        f.close()\n",
    "    ratings = np.array(ratings, dtype = np.float32)\n",
    "    # permute the ratings array\n",
    "    ratings = np.random.permutation(ratings)\n",
    "    print(\"Loading data done\")\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_split_data(data_size, test_p):\n",
    "    # Load data and split into train set, test set randomly.\n",
    "    # data_size is either \"100k\", \"1m\", \"10m\" or \"20m\".\n",
    "    # test_p is a float between 0 - 1 indicating the portion of data hold out as test set\n",
    "    print(\"split data randomly\")\n",
    "    # Load ratings, data is already permuted in get_data\n",
    "    ratings = get_data(data_size)\n",
    "    nb_users = int(np.max(ratings[:, 0]))\n",
    "    nb_movies = int(np.max(ratings[:, 1]))\n",
    "    # split test/train set\n",
    "    test_size = int(len(ratings) * test_p)\n",
    "    test_ratings = ratings[:test_size]\n",
    "    train_ratings = ratings[test_size:]\n",
    "    # train_ratings is converted into a matrix\n",
    "    train_M = np.zeros((nb_movies, nb_users), dtype = np.float32)\n",
    "    for rating in train_ratings:\n",
    "        train_M[int(rating[1]-1), int(rating[0]-1)] = rating[2]\n",
    "    # save test and train data in case more training is needed on this split\n",
    "    np.save(\"Data/\" + data_size + \"_\" + str(int(test_p * 100))+ \"percent_test.npy\", test_ratings)\n",
    "    np.save(\"Data/\" + data_size + \"_\" + str(int(test_p * 100))+ \"percent_trainM.npy\", train_M)\n",
    "    # test_ratings is numpy array of user id | item id | rating\n",
    "    # train_M is numpy array with nb_movies rows and nb_users columns, missing entries are filled with zero\n",
    "    return test_ratings, train_M, nb_users, nb_movies, len(train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ratings, train_M, nb_users, nb_movies, k = load_split_data(\"100k\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"Data/wine_zeroone.csv\",header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mask = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mask[X != 0] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_input_dim = X.shape[1]\n",
    "nn_output_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "b1 = np.zeros((1, nn_hdim))\n",
    "W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
    "b2 = np.zeros((1, nn_output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 4)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loss: \n",
      "7393.3561847\n",
      "1\n",
      "Loss: \n",
      "3122.4595546\n",
      "2\n",
      "Loss: \n",
      "1473.16005037\n",
      "3\n",
      "Loss: \n",
      "775.107615151\n",
      "4\n",
      "Loss: \n",
      "467.112292796\n",
      "5\n",
      "Loss: \n",
      "328.330289818\n",
      "6\n",
      "Loss: \n",
      "265.065049092\n",
      "7\n",
      "Loss: \n",
      "236.017196568\n",
      "8\n",
      "Loss: \n",
      "222.607563204\n",
      "9\n",
      "Loss: \n",
      "216.381772862\n",
      "10\n",
      "Loss: \n",
      "213.466705894\n",
      "11\n",
      "Loss: \n",
      "212.080644676\n",
      "12\n",
      "Loss: \n",
      "211.401780412\n",
      "13\n",
      "Loss: \n",
      "211.050385078\n",
      "14\n",
      "Loss: \n",
      "210.850784569\n",
      "15\n",
      "Loss: \n",
      "210.721634769\n",
      "16\n",
      "Loss: \n",
      "210.625245212\n",
      "17\n",
      "Loss: \n",
      "210.544143082\n",
      "18\n",
      "Loss: \n",
      "210.470224621\n",
      "19\n",
      "Loss: \n",
      "210.399729774\n",
      "20\n",
      "Loss: \n",
      "210.330913064\n",
      "21\n",
      "Loss: \n",
      "210.262963647\n",
      "22\n",
      "Loss: \n",
      "210.1955044\n",
      "23\n",
      "Loss: \n",
      "210.128359519\n",
      "24\n",
      "Loss: \n",
      "210.061446668\n",
      "25\n",
      "Loss: \n",
      "209.99472691\n",
      "26\n",
      "Loss: \n",
      "209.928181473\n",
      "27\n",
      "Loss: \n",
      "209.861800949\n",
      "28\n",
      "Loss: \n",
      "209.79558029\n",
      "29\n",
      "Loss: \n",
      "209.729516473\n",
      "30\n",
      "Loss: \n",
      "209.663607423\n",
      "31\n",
      "Loss: \n",
      "209.597851511\n",
      "32\n",
      "Loss: \n",
      "209.532247317\n",
      "33\n",
      "Loss: \n",
      "209.466793525\n",
      "34\n",
      "Loss: \n",
      "209.401488872\n",
      "35\n",
      "Loss: \n",
      "209.336332121\n",
      "36\n",
      "Loss: \n",
      "209.271322056\n",
      "37\n",
      "Loss: \n",
      "209.206457474\n",
      "38\n",
      "Loss: \n",
      "209.141737181\n",
      "39\n",
      "Loss: \n",
      "209.077159994\n",
      "40\n",
      "Loss: \n",
      "209.012724737\n",
      "41\n",
      "Loss: \n",
      "208.948430244\n",
      "42\n",
      "Loss: \n",
      "208.884275358\n",
      "43\n",
      "Loss: \n",
      "208.820258928\n",
      "44\n",
      "Loss: \n",
      "208.756379814\n",
      "45\n",
      "Loss: \n",
      "208.692636882\n",
      "46\n",
      "Loss: \n",
      "208.629029007\n",
      "47\n",
      "Loss: \n",
      "208.565555073\n",
      "48\n",
      "Loss: \n",
      "208.502213969\n",
      "49\n",
      "Loss: \n",
      "208.439004595\n",
      "50\n",
      "Loss: \n",
      "208.375925857\n",
      "51\n",
      "Loss: \n",
      "208.312976669\n",
      "52\n",
      "Loss: \n",
      "208.250155954\n",
      "53\n",
      "Loss: \n",
      "208.18746264\n",
      "54\n",
      "Loss: \n",
      "208.124895665\n",
      "55\n",
      "Loss: \n",
      "208.062453973\n",
      "56\n",
      "Loss: \n",
      "208.000136516\n",
      "57\n",
      "Loss: \n",
      "207.937942254\n",
      "58\n",
      "Loss: \n",
      "207.875870153\n",
      "59\n",
      "Loss: \n",
      "207.813919186\n",
      "60\n",
      "Loss: \n",
      "207.752088335\n",
      "61\n",
      "Loss: \n",
      "207.690376587\n",
      "62\n",
      "Loss: \n",
      "207.628782939\n",
      "63\n",
      "Loss: \n",
      "207.567306391\n",
      "64\n",
      "Loss: \n",
      "207.505945952\n",
      "65\n",
      "Loss: \n",
      "207.44470064\n",
      "66\n",
      "Loss: \n",
      "207.383569476\n",
      "67\n",
      "Loss: \n",
      "207.322551489\n",
      "68\n",
      "Loss: \n",
      "207.261645717\n",
      "69\n",
      "Loss: \n",
      "207.200851201\n",
      "70\n",
      "Loss: \n",
      "207.140166991\n",
      "71\n",
      "Loss: \n",
      "207.079592143\n",
      "72\n",
      "Loss: \n",
      "207.01912572\n",
      "73\n",
      "Loss: \n",
      "206.95876679\n",
      "74\n",
      "Loss: \n",
      "206.898514428\n",
      "75\n",
      "Loss: \n",
      "206.838367717\n",
      "76\n",
      "Loss: \n",
      "206.778325743\n",
      "77\n",
      "Loss: \n",
      "206.718387601\n",
      "78\n",
      "Loss: \n",
      "206.658552391\n",
      "79\n",
      "Loss: \n",
      "206.598819219\n",
      "80\n",
      "Loss: \n",
      "206.539187198\n",
      "81\n",
      "Loss: \n",
      "206.479655447\n",
      "82\n",
      "Loss: \n",
      "206.420223089\n",
      "83\n",
      "Loss: \n",
      "206.360889255\n",
      "84\n",
      "Loss: \n",
      "206.301653081\n",
      "85\n",
      "Loss: \n",
      "206.24251371\n",
      "86\n",
      "Loss: \n",
      "206.183470288\n",
      "87\n",
      "Loss: \n",
      "206.124521971\n",
      "88\n",
      "Loss: \n",
      "206.065667916\n",
      "89\n",
      "Loss: \n",
      "206.006907289\n",
      "90\n",
      "Loss: \n",
      "205.948239261\n",
      "91\n",
      "Loss: \n",
      "205.889663008\n",
      "92\n",
      "Loss: \n",
      "205.83117771\n",
      "93\n",
      "Loss: \n",
      "205.772782556\n",
      "94\n",
      "Loss: \n",
      "205.714476738\n",
      "95\n",
      "Loss: \n",
      "205.656259454\n",
      "96\n",
      "Loss: \n",
      "205.598129906\n",
      "97\n",
      "Loss: \n",
      "205.540087304\n",
      "98\n",
      "Loss: \n",
      "205.482130862\n",
      "99\n",
      "Loss: \n",
      "205.424259798\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "Flag = True\n",
    "for i in xrange(0, 100):\n",
    "    print i\n",
    "#     if i > 600 and Flag:\n",
    "#         epsilon *= 0.5\n",
    "#         Flag = False\n",
    "\n",
    "    # Forward propagation\n",
    "    #print \"W1:\"\n",
    "    #print W1\n",
    "    z1 = X.dot(W1) + b1\n",
    "    #print \"z1:\"\n",
    "    #print z1\n",
    "    a1 = sigmoid(z1)\n",
    "    #print \"a1\"\n",
    "    #print a1\n",
    "    #print \"W2\"\n",
    "    #print W2\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    #print \"z2\"\n",
    "    #print z2\n",
    "    loss = np.sum(np.square(X - z2) * X_mask)\n",
    "    loss += (reg_lambda/2) * (1.0/ X.shape[0]) * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
    "    L.append(loss)\n",
    "    print \"Loss: \"\n",
    "    print loss\n",
    "\n",
    "    # Backpropagation\n",
    "    delta3 = (z2 - X) * X_mask\n",
    "    #print \"delta3:\"\n",
    "    #print delta3\n",
    "    dW2 = (a1.T).dot(delta3)\n",
    "    #print \"dw2:\"\n",
    "    #print dW2\n",
    "    db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "    #print \"db2\"\n",
    "    #print db2\n",
    "    delta2 = delta3.dot(W2.T) * a1 * (1 - a1)\n",
    "    #print \"delta2\"\n",
    "    #print delta2\n",
    "    dW1 = np.dot((X * X_mask).T, delta2)\n",
    "    #print \"dw1\"\n",
    "    #print dW1\n",
    "    db1 = np.sum(delta2, axis=0)\n",
    "    #print \"db1\"\n",
    "    #print db1\n",
    "    # Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "    dW2 += reg_lambda * W2\n",
    "    dW1 += reg_lambda * W1\n",
    "\n",
    "    # Gradient descent parameter update\n",
    "    W1 += -epsilon * dW1\n",
    "    b1 += -epsilon * db1\n",
    "    W2 += -epsilon * dW2\n",
    "    b2 += -epsilon * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a199810>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAFkCAYAAACJu/k0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d320d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34615385,  0.25490196,  0.25301205, ...,  0.36363636,\n",
       "         0.36046512,  0.53225806],\n",
       "       [ 0.17307692,  0.30392157,  0.        , ...,  0.50909091,\n",
       "         0.1627907 ,  0.        ],\n",
       "       [ 0.46153846,  0.        ,  0.        , ...,  0.34545455,\n",
       "         0.39534884,  0.4516129 ],\n",
       "       ..., \n",
       "       [ 0.33653846,  0.14705882,  0.22289157, ...,  0.        ,\n",
       "         0.        ,  0.67741935],\n",
       "       [ 0.        ,  0.31372549,  0.        , ...,  0.58181818,\n",
       "         0.        ,  0.74193548],\n",
       "       [ 0.        ,  0.07843137,  0.18072289, ...,  0.6       ,\n",
       "         0.25581395,  0.51612903]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_oracle = pd.read_csv(\"Data/wine_zeroone_oracle.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297.74476714273322"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((z2 - X_oracle.values) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bg end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_M = pd.read_csv(\"Data/wine_zc.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_M = train_M.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_movies = train_M.shape[0]\n",
    "nb_users = train_M.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_M = train_M.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_M = np.zeros((nb_movies, nb_users), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RMSE_list = [0] * nb_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.dvector(\"input\")\n",
    "X_observed = T.dvector(\"observedIndex\")\n",
    "update_matrix = T.matrix(\"updateIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = theano.shared(np.random.randn(nb_hunits, nb_users), name='V')\n",
    "miu = theano.shared(np.zeros(nb_hunits), name='miu')\n",
    "W = theano.shared(np.random.randn(nb_users, nb_hunits), name='W')\n",
    "b = theano.shared(np.zeros(nb_users), name='b')\n",
    "z1 = T.nnet.sigmoid(V.dot(X) + miu)\n",
    "z2 = W.dot(z1) + b\n",
    "loss_reg = 1.0/nb_movies * lambda_reg/2 * (T.sum(T.sqr(V)) + T.sum(T.sqr(W)))\n",
    "loss = T.sum(T.sqr((X - z2) * X_observed)) + loss_reg\n",
    "gV, gmiu, gW, gb = T.grad(loss, [V, miu, W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function(\n",
    "      inputs=[X, X_observed, update_matrix],\n",
    "      outputs=[z2],\n",
    "      updates=((V, V - learningrate * gV * update_matrix),(miu, miu - learningrate * gmiu),\n",
    "          (W, W - learningrate * gW * update_matrix.T), (b, b - learningrate * gb * X_observed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(nb_epoch):\n",
    "    print(str(j + 1) + \" epoch\")\n",
    "    l = 0\n",
    "    for i in np.random.permutation(nb_movies):\n",
    "        Ri = train_M[i, :]\n",
    "        Ri_observed = Ri.copy()\n",
    "        Ri_observed[Ri != 0] = 1\n",
    "\n",
    "        \n",
    "        update_m = np.tile(Ri_observed, (nb_hunits, 1))\n",
    "        Ri_predicted = train(Ri, Ri_observed, update_m)\n",
    "        prediction_M[i, :] = np.array(Ri_predicted)\n",
    "        l += sum(np.square(prediction_M[i,:]-Ri))\n",
    "    print \"Loss: \" + str(l)\n",
    "        \n",
    "    #RMSE_list[j] = cal_RMSE(prediction_M, test_ratings)\n",
    "\n",
    "print(\"training complete\")\n",
    "#return nb_epoch, RMSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_M[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_M[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_RMSE(prediction_M, test_ratings):\n",
    "    RMSE = 0\n",
    "    for rating in test_ratings:\n",
    "        RMSE += (rating[2] - prediction_M[int(rating[1] - 1), int(rating[0] - 1)])**2\n",
    "    RMSE = math.sqrt(RMSE / len(test_ratings))\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_auto(data_size = \"100k\", nb_epoch = 10, test_p = 0.1, nb_hunits = 10, lambda_reg = 0.001, learningrate = 0.01):\n",
    "    test_ratings, train_M, nb_users, nb_movies, k = load_split_data(data_size, test_p)\n",
    "    prediction_M = np.zeros((nb_movies, nb_users), dtype = np.float32)\n",
    "    RMSE_list = [0] * nb_epoch\n",
    "\n",
    "    # set up theano autoencoder structure and update function\n",
    "    X = T.dvector(\"input\")\n",
    "    X_observed = T.dvector(\"observedIndex\")\n",
    "    update_matrix = T.matrix(\"updateIndex\")\n",
    "    V = theano.shared(np.random.randn(nb_hunits, nb_users), name='V')\n",
    "    miu = theano.shared(np.zeros(nb_hunits), name='miu')\n",
    "    W = theano.shared(np.random.randn(nb_users, nb_hunits), name='W')\n",
    "    b = theano.shared(np.zeros(nb_users), name='b')\n",
    "    z1 = T.nnet.sigmoid(V.dot(X) + miu)\n",
    "    z2 = W.dot(z1) + b\n",
    "    loss_reg = 1.0/nb_movies * lambda_reg/2 * (T.sum(T.sqr(V)) + T.sum(T.sqr(W)))\n",
    "    loss = T.sum(T.sqr((X - z2) * X_observed)) + loss_reg\n",
    "    gV, gmiu, gW, gb = T.grad(loss, [V, miu, W, b])\n",
    "\n",
    "    train = theano.function(\n",
    "          inputs=[X, X_observed, update_matrix],\n",
    "          outputs=[z2],\n",
    "          updates=((V, V - learningrate * gV * update_matrix),(miu, miu - learningrate * gmiu),\n",
    "              (W, W - learningrate * gW * update_matrix.T), (b, b - learningrate * gb * X_observed)))\n",
    "\n",
    "    for j in range(nb_epoch):\n",
    "        print(str(j + 1) + \" epoch\")\n",
    "        for i in np.random.permutation(nb_movies):\n",
    "            Ri = train_M[i, :]\n",
    "            Ri_observed = Ri.copy()\n",
    "            Ri_observed[Ri > 0] = 1\n",
    "            update_m = np.tile(Ri_observed, (nb_hunits, 1))\n",
    "            Ri_predicted = train(Ri, Ri_observed, update_m)\n",
    "            prediction_M[i, :] = np.array(Ri_predicted)\n",
    "        RMSE_list[j] = cal_RMSE(prediction_M, test_ratings)\n",
    "\n",
    "    print(\"training complete\")\n",
    "    return nb_epoch, RMSE_list, Ri_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_auto()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
