{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(size):\n",
    "    ratings = []\n",
    "    if size == \"100k\":\n",
    "        path = \"../dat/rec/ml-100k/u.data\"\n",
    "        print(\"Read movie lens 100k data set\")\n",
    "        f = open(path, \"r\")\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            ratings.append(line.split()[0:-1])\n",
    "        f.close()\n",
    "    ratings = np.array(ratings, dtype = np.float32)\n",
    "    # permute the ratings array\n",
    "    ratings = np.random.permutation(ratings)\n",
    "    print(\"Loading data done\")\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read movie lens 100k data set\n",
      "Loading data done\n"
     ]
    }
   ],
   "source": [
    "ratings = get_data(\"100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_split_data(data_size, test_p):\n",
    "    # Load data and split into train set, test set randomly.\n",
    "    # data_size is either \"100k\", \"1m\", \"10m\" or \"20m\".\n",
    "    # test_p is a float between 0 - 1 indicating the portion of data hold out as test set\n",
    "    print(\"split data randomly\")\n",
    "    # Load ratings, data is already permuted in get_data\n",
    "    ratings = get_data(data_size)\n",
    "    nb_users = int(np.max(ratings[:, 0]))\n",
    "    nb_movies = int(np.max(ratings[:, 1]))\n",
    "    # split test/train set\n",
    "    test_size = int(len(ratings) * test_p)\n",
    "    test_ratings = ratings[:test_size]\n",
    "    train_ratings = ratings[test_size:]\n",
    "    # train_ratings is converted into a matrix\n",
    "    train_M = np.zeros((nb_movies, nb_users), dtype = np.float32)\n",
    "    for rating in train_ratings:\n",
    "        train_M[int(rating[1]-1), int(rating[0]-1)] = rating[2]\n",
    "    # save test and train data in case more training is needed on this split\n",
    "    np.save(\"../dat/rec/\" + data_size + \"_\" + str(int(test_p * 100))+ \"percent_test.npy\", test_ratings)\n",
    "    np.save(\"../dat/rec/\" + data_size + \"_\" + str(int(test_p * 100))+ \"percent_trainM.npy\", train_M)\n",
    "    # test_ratings is numpy array of user id | item id | rating\n",
    "    # train_M is numpy array with nb_movies rows and nb_users columns, missing entries are filled with zero\n",
    "    return test_ratings, train_M, nb_users, nb_movies, len(train_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cal_RMSE(prediction_M, test_ratings):\n",
    "#     RMSE = 0\n",
    "#     for rating in test_ratings:\n",
    "#         RMSE += (rating[2] - prediction_M[int(rating[1] - 1), int(rating[0] - 1)])**2\n",
    "#     RMSE = math.sqrt(RMSE / len(test_ratings))\n",
    "#     return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data randomly\n",
      "Read movie lens 100k data set\n",
      "Loading data done\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "test_p = 0.1\n",
    "nb_hunits = 10\n",
    "lambda_reg = 0.001\n",
    "learningrate = 0.01\n",
    "data_size = \"100k\"\n",
    "test_ratings, train_M, nb_users, nb_movies, k = load_split_data(data_size, test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_M = np.zeros((nb_movies, nb_users), dtype = np.float32) # 1682 x 943\n",
    "RMSE_list = [0] * nb_epoch # 1 x 10\n",
    "\n",
    "# set up theano autoencoder structure and update function\n",
    "X = T.dvector(\"input\")\n",
    "X_observed = T.dvector(\"observedIndex\")\n",
    "update_matrix = T.matrix(\"updateIndex\") # only 0 or 1\n",
    "V = theano.shared(np.random.randn(nb_hunits, nb_users), name='V')\n",
    "miu = theano.shared(np.zeros(nb_hunits), name='miu')\n",
    "W = theano.shared(np.random.randn(nb_users, nb_hunits), name='W')\n",
    "b = theano.shared(np.zeros(nb_users), name='b')\n",
    "z1 = T.nnet.sigmoid(V.dot(X) + miu)\n",
    "z2 = W.dot(z1) + b\n",
    "loss_reg = 1.0/nb_movies * lambda_reg/2 * (T.sum(T.sqr(V)) + T.sum(T.sqr(W)))\n",
    "loss = T.sum(T.sqr((X - z2) * X_observed)) + loss_reg\n",
    "gV, gmiu, gW, gb = T.grad(loss, [V, miu, W, b]) # gb is (dL / db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_auto():\n",
    "    \n",
    "    train = theano.function(\n",
    "      inputs=[X, X_observed, update_matrix],\n",
    "      outputs=[z2], # W += -epsilon * dW\n",
    "      updates=((V, V - learningrate * gV * update_matrix),(miu, miu - learningrate * gmiu),\n",
    "          (W, W - learningrate * gW * update_matrix.T), (b, b - learningrate * gb * X_observed)))\n",
    "    \n",
    "    for j in range(nb_epoch):\n",
    "        print(str(j + 1) + \" epoch\")\n",
    "        for i in np.random.permutation(nb_movies):\n",
    "            Ri = train_M[i, :] # (943, 1) or (1, 943) -> take (943, 1)\n",
    "            Ri_observed = Ri.copy()\n",
    "            Ri_observed[Ri > 0] = 1 # pick out rated value(observed)\n",
    "            update_m = np.tile(Ri_observed, (nb_hunits, 1)) # copy 10 columns for 10 hidden units\n",
    "            Ri_predicted = train(Ri, Ri_observed, update_m) \n",
    "            prediction_M[i, :] = np.array(Ri_predicted) # push_back into result, 1 column (943 x 1)\n",
    "    #         RMSE_list[j] = cal_RMSE(prediction_M, test_ratings)\n",
    "    print(\"training complete\")\n",
    "    return train_M, prediction_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch\n",
      "2 epoch\n",
      "3 epoch\n",
      "4 epoch\n",
      "5 epoch\n",
      "6 epoch\n",
      "7 epoch\n",
      "8 epoch\n",
      "9 epoch\n",
      "10 epoch\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "train_M, prediction_M = train_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8773241 ,  3.03445125,  2.54514933, ...,  3.51779461,\n",
       "         3.89729404,  3.29231882],\n",
       "       [ 3.27614784,  3.14767361,  2.12088227, ...,  3.67183399,\n",
       "         3.76286483,  3.63309455],\n",
       "       [ 3.94458914,  4.0529213 ,  3.79505682, ...,  4.49241924,\n",
       "         4.48526764,  3.91896939],\n",
       "       ..., \n",
       "       [ 0.42165658,  0.30078402,  1.14065456, ...,  1.9043963 ,\n",
       "         1.68626499,  0.6113947 ],\n",
       "       [ 1.74561405,  1.71814346,  1.93321943, ...,  1.52278507,\n",
       "         3.30635905,  1.65390396],\n",
       "       [ 0.26748362,  0.17551543,  1.27811289, ...,  1.88702881,\n",
       "         1.68359172,  0.65674895]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  4.,  0., ...,  5.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  5.],\n",
       "       [ 4.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.tile(np.array([2,1]), 3) # stands for repeat\n",
    "t = np.tile(np.array([2,1]), [10, 1])\n",
    "t2 = t.copy()\n",
    "t2[t == 1] = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
