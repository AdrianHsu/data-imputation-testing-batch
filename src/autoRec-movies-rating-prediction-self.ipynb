{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler,scale\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(size):\n",
    "    ratings = []\n",
    "    if size == \"100k\":\n",
    "        path = \"../dat/rec/ml-100k/u.data\"\n",
    "        print(\"Read movie lens 100k data set\")\n",
    "        f = open(path, \"r\")\n",
    "        while (1):\n",
    "            line = f.readline()\n",
    "            if line == \"\":\n",
    "                break\n",
    "            ratings.append(line.split()[0:-1])\n",
    "        f.close()\n",
    "    ratings = np.array(ratings, dtype = np.float32)\n",
    "    # permute the ratings array\n",
    "    ratings = np.random.permutation(ratings)\n",
    "    print(\"Loading data done\")\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read movie lens 100k data set\n",
      "Loading data done\n"
     ]
    }
   ],
   "source": [
    "ratings = get_data(\"100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_split_data(data_size, test_p):\n",
    "    # Load data and split into train set, test set randomly.\n",
    "    # data_size is either \"100k\", \"1m\", \"10m\" or \"20m\".\n",
    "    # test_p is a float between 0 - 1 indicating the portion of data hold out as test set\n",
    "    print(\"split data randomly\")\n",
    "    # Load ratings, data is already permuted in get_data\n",
    "    ratings = get_data(data_size)\n",
    "    nb_users = int(np.max(ratings[:, 0]))\n",
    "    nb_movies = int(np.max(ratings[:, 1]))\n",
    "    # split test/train set\n",
    "    test_size = int(len(ratings) * test_p)\n",
    "    test_ratings = ratings[:test_size]\n",
    "    train_ratings = ratings[test_size:]\n",
    "    # train_ratings is converted into a matrix\n",
    "    train_M = np.zeros((nb_movies, nb_users), dtype = np.float32)\n",
    "    for rating in train_ratings:\n",
    "        train_M[int(rating[1]-1), int(rating[0]-1)] = rating[2]\n",
    "    # save test and train data in case more training is needed on this split\n",
    "    np.save(\"../dat/rec/\" + data_size + \"_\" + str(int(test_p * 100))+ \"percent_test.npy\", test_ratings)\n",
    "    np.save(\"../dat/rec/\" + data_size + \"_\" + str(int(test_p * 100))+ \"percent_trainM.npy\", train_M)\n",
    "    # test_ratings is numpy array of user id | item id | rating\n",
    "    # train_M is numpy array with nb_movies rows and nb_users columns, missing entries are filled with zero\n",
    "    return test_ratings, train_M, nb_users, nb_movies, len(train_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cal_RMSE(prediction_M, test_ratings):\n",
    "#     RMSE = 0\n",
    "#     for rating in test_ratings:\n",
    "#         RMSE += (rating[2] - prediction_M[int(rating[1] - 1), int(rating[0] - 1)])**2\n",
    "#     RMSE = math.sqrt(RMSE / len(test_ratings))\n",
    "#     return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data randomly\n",
      "Read movie lens 100k data set\n",
      "Loading data done\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 1000\n",
    "test_p = 0.1\n",
    "nb_hunits = 10\n",
    "lambda_reg = 0.001\n",
    "epsilon = 1e-4 #learningrate\n",
    "reg_lambda = 0.01\n",
    "data_size = \"100k\"\n",
    "test_ratings, train_M, nb_users, nb_movies, k = load_split_data(data_size, test_p)\n",
    "prediction_M = np.zeros((nb_movies, nb_users), dtype = np.float32) # 1682 x 943\n",
    "RMSE_list = [0] * nb_epoch # 1 x 10\n",
    "L = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(X, X_observed, update_matrix):\n",
    "\n",
    "    W1 = np.random.randn(nb_users, nb_hunits) # 943 x 10\n",
    "    b1 = np.zeros((1, nb_hunits)) # 1 x 10\n",
    "    W2 = np.random.randn(nb_hunits, nb_users) # 10 x 943\n",
    "    b2 = np.zeros((1, nb_users)) # 1 x 943\n",
    "    a2 = np.zeros((nb_movies, nb_users)) # 1682 x 943\n",
    "    \n",
    "    for i in range(0, nb_epoch):\n",
    "\n",
    "        z1 = X.dot(W1) + b1 # 1682x943 dot 943x10\n",
    "        a1 = sigmoid(z1) # 1682x10\n",
    "        z2 = a1.dot(W2) + b2 #1682x10 dot 10x943\n",
    "#         a2 = sigmoid(z2) #1682x943\n",
    "        a2 = z2\n",
    "        tmp1 = np.sum(np.square(W1))\n",
    "        tmp2 = np.sum(np.square(W2))\n",
    "        loss_reg = (1.0/nb_movies) * (lambda_reg/2) * ( tmp1 + tmp2 )\n",
    "        loss = np.sum( np.square((X - a2) * X_observed) ) + loss_reg\n",
    "        L.append(loss)\n",
    "        print(\"Loss: \")\n",
    "        print(loss)\n",
    "        # Backpropagation\n",
    "#         delta2 = (a2 * (1 - a2)) * (a2 - X) # 1682x943\n",
    "        delta2 = (a2 - X)*X_observed\n",
    "        dW2 = (a1.T).dot(delta2) # 10x943\n",
    "        db2 = np.sum(delta2, axis=0, keepdims=True) # 1x943\n",
    "        delta1 = (a1 * (1 - a1)) * (delta2.dot(W2.T)) # 1682x943\n",
    "        dW1 = ((X*X_observed).T).dot(delta1) # 943x10\n",
    "        db1 = np.sum(delta1, axis=0) # 1x10\n",
    "        # Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "        dW2 += reg_lambda * W2\n",
    "        dW1 += reg_lambda * W1\n",
    "        \n",
    "        # Gradient descent parameter update\n",
    "        # original: 943x10 * 943x10\n",
    "        W1 += -epsilon * dW1# 943x1682 * 943x10\n",
    "        b1 += -epsilon * db1\n",
    "        W2 += -epsilon * dW2\n",
    "        b2 += -epsilon * db2\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_auto():\n",
    "        \n",
    "    Ri = train_M[:] # (1682, 943)\n",
    "    Ri_observed = Ri.copy()\n",
    "    Ri_observed[Ri > 0] = 1 # (1682, 943)\n",
    "    update_m = Ri_observed # \n",
    "    Ri_predicted = train(Ri, Ri_observed, update_m)\n",
    "    prediction_M = Ri_predicted\n",
    "#         RMSE_list[j] = cal_RMSE(prediction_M, test_ratings)\n",
    "    print(\"training complete\")\n",
    "    return train_M, prediction_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: \n",
      "1620967.22993\n",
      "Loss: \n",
      "1347427.18573\n",
      "Loss: \n",
      "1221566.28738\n",
      "Loss: \n",
      "1121491.03415\n",
      "Loss: \n",
      "1035009.29611\n",
      "Loss: \n",
      "960261.372216\n",
      "Loss: \n",
      "893247.710084\n",
      "Loss: \n",
      "834394.021878\n",
      "Loss: \n",
      "781123.248958\n",
      "Loss: \n",
      "734215.754982\n",
      "Loss: \n",
      "690964.195488\n",
      "Loss: \n",
      "652054.228715\n",
      "Loss: \n",
      "617193.181226\n",
      "Loss: \n",
      "582160.287684\n",
      "Loss: \n",
      "552510.765531\n",
      "Loss: \n",
      "524039.851036\n",
      "Loss: \n",
      "499200.298355\n",
      "Loss: \n",
      "476055.285852\n",
      "Loss: \n",
      "455369.946261\n",
      "Loss: \n",
      "436490.255\n",
      "Loss: \n",
      "418913.364829\n",
      "Loss: \n",
      "401970.649198\n",
      "Loss: \n",
      "387285.200983\n",
      "Loss: \n",
      "374379.690996\n",
      "Loss: \n",
      "362400.107203\n",
      "Loss: \n",
      "350959.652488\n",
      "Loss: \n",
      "340155.152494\n",
      "Loss: \n",
      "330719.689411\n",
      "Loss: \n",
      "321808.57511\n",
      "Loss: \n",
      "313338.47225\n",
      "Loss: \n",
      "305336.997702\n",
      "Loss: \n",
      "298020.103419\n",
      "Loss: \n",
      "290846.329109\n",
      "Loss: \n",
      "284117.619177\n",
      "Loss: \n",
      "277537.10844\n",
      "Loss: \n",
      "271462.960254\n",
      "Loss: \n",
      "265865.099213\n",
      "Loss: \n",
      "260630.02901\n",
      "Loss: \n",
      "255338.162695\n",
      "Loss: \n",
      "250505.450256\n",
      "Loss: \n",
      "245876.526011\n",
      "Loss: \n",
      "241486.375193\n",
      "Loss: \n",
      "237325.023282\n",
      "Loss: \n",
      "233508.937598\n",
      "Loss: \n",
      "229767.441007\n",
      "Loss: \n",
      "226297.171442\n",
      "Loss: \n",
      "222757.920921\n",
      "Loss: \n",
      "219253.99691\n",
      "Loss: \n",
      "215444.251449\n",
      "Loss: \n",
      "212309.005877\n",
      "Loss: \n",
      "208931.767964\n",
      "Loss: \n",
      "206191.623074\n",
      "Loss: \n",
      "203710.088599\n",
      "Loss: \n",
      "201209.466619\n",
      "Loss: \n",
      "198619.808468\n",
      "Loss: \n",
      "196113.263542\n",
      "Loss: \n",
      "193709.928405\n",
      "Loss: \n",
      "191056.772836\n",
      "Loss: \n",
      "188666.703208\n",
      "Loss: \n",
      "186221.622497\n",
      "Loss: \n",
      "184132.578939\n",
      "Loss: \n",
      "182098.368817\n",
      "Loss: \n",
      "180193.135967\n",
      "Loss: \n",
      "178474.244928\n",
      "Loss: \n",
      "176672.536782\n",
      "Loss: \n",
      "174938.056579\n",
      "Loss: \n",
      "173240.685457\n",
      "Loss: \n",
      "171664.320221\n",
      "Loss: \n",
      "170206.812513\n",
      "Loss: \n",
      "168721.131433\n",
      "Loss: \n",
      "167409.641161\n",
      "Loss: \n",
      "165966.221012\n",
      "Loss: \n",
      "164541.22739\n",
      "Loss: \n",
      "163139.848178\n",
      "Loss: \n",
      "161811.07371\n",
      "Loss: \n",
      "160531.086142\n",
      "Loss: \n",
      "159322.40697\n",
      "Loss: \n",
      "158071.532061\n",
      "Loss: \n",
      "156905.118944\n",
      "Loss: \n",
      "155775.972444\n",
      "Loss: \n",
      "154664.758488\n",
      "Loss: \n",
      "153595.616253\n",
      "Loss: \n",
      "152581.10756\n",
      "Loss: \n",
      "151604.591387\n",
      "Loss: \n",
      "150699.416496\n",
      "Loss: \n",
      "149751.135171\n",
      "Loss: \n",
      "148929.367545\n",
      "Loss: \n",
      "148010.287722\n",
      "Loss: \n",
      "147121.025136\n",
      "Loss: \n",
      "146231.065991\n",
      "Loss: \n",
      "145409.853119\n",
      "Loss: \n",
      "144660.757188\n",
      "Loss: \n",
      "143810.116025\n",
      "Loss: \n",
      "143115.731571\n",
      "Loss: \n",
      "142271.567467\n",
      "Loss: \n",
      "141668.225012\n",
      "Loss: \n",
      "141069.790625\n",
      "Loss: \n",
      "140305.065146\n",
      "Loss: \n",
      "139593.548012\n",
      "Loss: \n",
      "138919.338842\n",
      "Loss: \n",
      "138273.825082\n",
      "Loss: \n",
      "137646.044556\n",
      "Loss: \n",
      "137032.686208\n",
      "Loss: \n",
      "136432.297354\n",
      "Loss: \n",
      "135844.218853\n",
      "Loss: \n",
      "135268.148638\n",
      "Loss: \n",
      "134704.292671\n",
      "Loss: \n",
      "134153.771503\n",
      "Loss: \n",
      "133616.892575\n",
      "Loss: \n",
      "133093.060963\n",
      "Loss: \n",
      "132579.080479\n",
      "Loss: \n",
      "132070.779901\n",
      "Loss: \n",
      "131562.46432\n",
      "Loss: \n",
      "131058.533821\n",
      "Loss: \n",
      "130577.334943\n",
      "Loss: \n",
      "130109.909968\n",
      "Loss: \n",
      "129654.464689\n",
      "Loss: \n",
      "129210.083014\n",
      "Loss: \n",
      "128776.048881\n",
      "Loss: \n",
      "128352.492066\n",
      "Loss: \n",
      "127937.883521\n",
      "Loss: \n",
      "127531.108743\n",
      "Loss: \n",
      "127136.569701\n",
      "Loss: \n",
      "126789.168777\n",
      "Loss: \n",
      "126371.904202\n",
      "Loss: \n",
      "126070.826956\n",
      "Loss: \n",
      "125650.918959\n",
      "Loss: \n",
      "125203.595062\n",
      "Loss: \n",
      "124769.316619\n",
      "Loss: \n",
      "124360.327248\n",
      "Loss: \n",
      "123947.309639\n",
      "Loss: \n",
      "123718.184198\n",
      "Loss: \n",
      "123326.140396\n",
      "Loss: \n",
      "122978.016561\n",
      "Loss: \n",
      "122631.165166\n",
      "Loss: \n",
      "122298.801302\n",
      "Loss: \n",
      "121979.655535\n",
      "Loss: \n",
      "121667.587732\n",
      "Loss: \n",
      "121378.490693\n",
      "Loss: \n",
      "121221.968358\n",
      "Loss: \n",
      "121007.981606\n",
      "Loss: \n",
      "120661.646186\n",
      "Loss: \n",
      "120351.976233\n",
      "Loss: \n",
      "120049.126596\n",
      "Loss: \n",
      "119746.378727\n",
      "Loss: \n",
      "119450.049111\n",
      "Loss: \n",
      "119173.887432\n",
      "Loss: \n",
      "118942.11477\n",
      "Loss: \n",
      "118754.000095\n",
      "Loss: \n",
      "118612.551522\n",
      "Loss: \n",
      "118329.412899\n",
      "Loss: \n",
      "118068.015777\n",
      "Loss: \n",
      "117811.990894\n",
      "Loss: \n",
      "117554.609946\n",
      "Loss: \n",
      "117308.347003\n",
      "Loss: \n",
      "117074.404998\n",
      "Loss: \n",
      "116843.083688\n",
      "Loss: \n",
      "116610.753222\n",
      "Loss: \n",
      "116372.748386\n",
      "Loss: \n",
      "116135.843237\n",
      "Loss: \n",
      "115912.879025\n",
      "Loss: \n",
      "115624.278553\n",
      "Loss: \n",
      "115267.590088\n",
      "Loss: \n",
      "115029.486115\n",
      "Loss: \n",
      "114808.888476\n",
      "Loss: \n",
      "114592.928637\n",
      "Loss: \n",
      "114375.334744\n",
      "Loss: \n",
      "114162.59856\n",
      "Loss: \n",
      "113958.02535\n",
      "Loss: \n",
      "113754.770895\n",
      "Loss: \n",
      "113560.733882\n",
      "Loss: \n",
      "113380.6573\n",
      "Loss: \n",
      "113248.612799\n",
      "Loss: \n",
      "113031.37412\n",
      "Loss: \n",
      "112907.05238\n",
      "Loss: \n",
      "112645.258108\n",
      "Loss: \n",
      "112355.638742\n",
      "Loss: \n",
      "112182.845705\n",
      "Loss: \n",
      "112046.802193\n",
      "Loss: \n",
      "111927.844841\n",
      "Loss: \n",
      "111857.329195\n",
      "Loss: \n",
      "111653.332225\n",
      "Loss: \n",
      "111474.952557\n",
      "Loss: \n",
      "111292.22855\n",
      "Loss: \n",
      "111119.754035\n",
      "Loss: \n",
      "110946.407168\n",
      "Loss: \n",
      "110778.303862\n",
      "Loss: \n",
      "110621.971717\n",
      "Loss: \n",
      "110470.780008\n",
      "Loss: \n",
      "110326.885469\n",
      "Loss: \n",
      "110199.001343\n",
      "Loss: \n",
      "110137.039387\n",
      "Loss: \n",
      "110088.228237\n",
      "Loss: \n",
      "109890.033031\n",
      "Loss: \n",
      "109685.662138\n",
      "Loss: \n",
      "109534.736558\n",
      "Loss: \n",
      "109378.007383\n",
      "Loss: \n",
      "109237.024523\n",
      "Loss: \n",
      "109108.276776\n",
      "Loss: \n",
      "108986.437954\n",
      "Loss: \n",
      "108892.634171\n",
      "Loss: \n",
      "108801.029968\n",
      "Loss: \n",
      "108779.085716\n",
      "Loss: \n",
      "108630.207546\n",
      "Loss: \n",
      "108491.890392\n",
      "Loss: \n",
      "108349.251429\n",
      "Loss: \n",
      "108226.624699\n",
      "Loss: \n",
      "108116.988209\n",
      "Loss: \n",
      "108016.28337\n",
      "Loss: \n",
      "107960.985011\n",
      "Loss: \n",
      "107803.337168\n",
      "Loss: \n",
      "107703.835994\n",
      "Loss: \n",
      "107647.188657\n",
      "Loss: \n",
      "107647.627496\n",
      "Loss: \n",
      "107504.628355\n",
      "Loss: \n",
      "107367.186574\n",
      "Loss: \n",
      "107238.543818\n",
      "Loss: \n",
      "107135.882184\n",
      "Loss: \n",
      "107057.477917\n",
      "Loss: \n",
      "107049.266867\n",
      "Loss: \n",
      "106903.64186\n",
      "Loss: \n",
      "106775.511066\n",
      "Loss: \n",
      "106682.088978\n",
      "Loss: \n",
      "106629.812942\n",
      "Loss: \n",
      "106636.68226\n",
      "Loss: \n",
      "106502.630738\n",
      "Loss: \n",
      "106374.07534\n",
      "Loss: \n",
      "106254.624208\n",
      "Loss: \n",
      "106160.16236\n",
      "Loss: \n",
      "106075.736168\n",
      "Loss: \n",
      "106033.904467\n",
      "Loss: \n",
      "105893.536187\n",
      "Loss: \n",
      "105833.19991\n",
      "Loss: \n",
      "105727.590495\n",
      "Loss: \n",
      "105731.631802\n",
      "Loss: \n",
      "105599.259337\n",
      "Loss: \n",
      "105489.803728\n",
      "Loss: \n",
      "105412.328773\n",
      "Loss: \n",
      "105374.397655\n",
      "Loss: \n",
      "105391.839341\n",
      "Loss: \n",
      "105274.947234\n",
      "Loss: \n",
      "105163.290846\n",
      "Loss: \n",
      "105067.612142\n",
      "Loss: \n",
      "104992.836057\n",
      "Loss: \n",
      "104947.839619\n",
      "Loss: \n",
      "104962.444189\n",
      "Loss: \n",
      "104849.401579\n",
      "Loss: \n",
      "104737.217681\n",
      "Loss: \n",
      "104659.129688\n",
      "Loss: \n",
      "104604.789273\n",
      "Loss: \n",
      "104563.098102\n",
      "Loss: \n",
      "104577.549705\n",
      "Loss: \n",
      "104465.560554\n",
      "Loss: \n",
      "104351.549252\n",
      "Loss: \n",
      "104221.254802\n",
      "Loss: \n",
      "104139.818125\n",
      "Loss: \n",
      "104070.411841\n",
      "Loss: \n",
      "104024.298026\n",
      "Loss: \n",
      "104036.296898\n",
      "Loss: \n",
      "103924.968289\n",
      "Loss: \n",
      "103828.194047\n",
      "Loss: \n",
      "103761.637215\n",
      "Loss: \n",
      "103712.207688\n",
      "Loss: \n",
      "103716.798818\n",
      "Loss: \n",
      "103595.832093\n",
      "Loss: \n",
      "103540.030618\n",
      "Loss: \n",
      "103541.108341\n",
      "Loss: \n",
      "103413.900217\n",
      "Loss: \n",
      "103330.396581\n",
      "Loss: \n",
      "103302.77571\n",
      "Loss: \n",
      "103180.411787\n",
      "Loss: \n",
      "103113.349425\n",
      "Loss: \n",
      "103062.347939\n",
      "Loss: \n",
      "103055.242921\n",
      "Loss: \n",
      "103071.434668\n",
      "Loss: \n",
      "102970.196614\n",
      "Loss: \n",
      "102879.524522\n",
      "Loss: \n",
      "102784.378291\n",
      "Loss: \n",
      "102716.061684\n",
      "Loss: \n",
      "102657.786288\n",
      "Loss: \n",
      "102622.136459\n",
      "Loss: \n",
      "102618.270566\n",
      "Loss: \n",
      "102504.527956\n",
      "Loss: \n",
      "102400.109281\n",
      "Loss: \n",
      "102330.164262\n",
      "Loss: \n",
      "102274.698647\n",
      "Loss: \n",
      "102235.136701\n",
      "Loss: \n",
      "102236.851839\n",
      "Loss: \n",
      "102138.682469\n",
      "Loss: \n",
      "102066.77635\n",
      "Loss: \n",
      "102010.584432\n",
      "Loss: \n",
      "101964.622337\n",
      "Loss: \n",
      "101961.751037\n",
      "Loss: \n",
      "101860.902384\n",
      "Loss: \n",
      "101795.444429\n",
      "Loss: \n",
      "101752.386665\n",
      "Loss: \n",
      "101711.219431\n",
      "Loss: \n",
      "101722.585064\n",
      "Loss: \n",
      "101616.775549\n",
      "Loss: \n",
      "101523.850746\n",
      "Loss: \n",
      "101456.996228\n",
      "Loss: \n",
      "101394.009623\n",
      "Loss: \n",
      "101335.38573\n",
      "Loss: \n",
      "101283.104649\n",
      "Loss: \n",
      "101258.656581\n",
      "Loss: \n",
      "101207.022311\n",
      "Loss: \n",
      "101229.854961\n",
      "Loss: \n",
      "101124.558748\n",
      "Loss: \n",
      "101028.647283\n",
      "Loss: \n",
      "100958.813356\n",
      "Loss: \n",
      "100898.492965\n",
      "Loss: \n",
      "100854.814705\n",
      "Loss: \n",
      "100844.297529\n",
      "Loss: \n",
      "100772.55709\n",
      "Loss: \n",
      "100775.87019\n",
      "Loss: \n",
      "100674.418761\n",
      "Loss: \n",
      "100631.761932\n",
      "Loss: \n",
      "100612.605264\n",
      "Loss: \n",
      "100581.474927\n",
      "Loss: \n",
      "100613.329654\n",
      "Loss: \n",
      "100521.779193\n",
      "Loss: \n",
      "100440.283445\n",
      "Loss: \n",
      "100395.83529\n",
      "Loss: \n",
      "100359.487991\n",
      "Loss: \n",
      "100344.322694\n",
      "Loss: \n",
      "100373.051421\n",
      "Loss: \n",
      "100284.041248\n",
      "Loss: \n",
      "100210.537562\n",
      "Loss: \n",
      "100167.091953\n",
      "Loss: \n",
      "100127.519801\n",
      "Loss: \n",
      "100093.120342\n",
      "Loss: \n",
      "100081.178464\n",
      "Loss: \n",
      "100107.236628\n",
      "Loss: \n",
      "100010.540399\n",
      "Loss: \n",
      "99928.4020477\n",
      "Loss: \n",
      "99879.0590078\n",
      "Loss: \n",
      "99845.5595911\n",
      "Loss: \n",
      "99844.6152165\n",
      "Loss: \n",
      "99770.4857096\n",
      "Loss: \n",
      "99749.4323461\n",
      "Loss: \n",
      "99722.9018226\n",
      "Loss: \n",
      "99746.7480826\n",
      "Loss: \n",
      "99657.1028745\n",
      "Loss: \n",
      "99580.1150084\n",
      "Loss: \n",
      "99531.9072086\n",
      "Loss: \n",
      "99485.8130995\n",
      "Loss: \n",
      "99442.6440607\n",
      "Loss: \n",
      "99412.300537\n",
      "Loss: \n",
      "99366.588003\n",
      "Loss: \n",
      "99367.0715777\n",
      "Loss: \n",
      "99268.4364829\n",
      "Loss: \n",
      "99192.1858701\n",
      "Loss: \n",
      "99147.7802289\n",
      "Loss: \n",
      "99107.6099425\n",
      "Loss: \n",
      "99070.1850408\n",
      "Loss: \n",
      "99036.7684491\n",
      "Loss: \n",
      "99022.832031\n",
      "Loss: \n",
      "99043.798832\n",
      "Loss: \n",
      "98952.9368331\n",
      "Loss: \n",
      "98890.3218141\n",
      "Loss: \n",
      "98856.7714415\n",
      "Loss: \n",
      "98837.2414195\n",
      "Loss: \n",
      "98852.9603482\n",
      "Loss: \n",
      "98772.6909659\n",
      "Loss: \n",
      "98743.6621402\n",
      "Loss: \n",
      "98736.2869215\n",
      "Loss: \n",
      "98677.0031766\n",
      "Loss: \n",
      "98646.4510667\n",
      "Loss: \n",
      "98591.7420866\n",
      "Loss: \n",
      "98592.2505481\n",
      "Loss: \n",
      "98514.5032034\n",
      "Loss: \n",
      "98485.2246098\n",
      "Loss: \n",
      "98468.4197392\n",
      "Loss: \n",
      "98488.5282942\n",
      "Loss: \n",
      "98405.1157211\n",
      "Loss: \n",
      "98375.1471669\n",
      "Loss: \n",
      "98356.3202031\n",
      "Loss: \n",
      "98352.700285\n",
      "Loss: \n",
      "98385.7748453\n",
      "Loss: \n",
      "98299.3081723\n",
      "Loss: \n",
      "98236.4317551\n",
      "Loss: \n",
      "98199.9749216\n",
      "Loss: \n",
      "98168.1007659\n",
      "Loss: \n",
      "98152.17195\n",
      "Loss: \n",
      "98106.8342299\n",
      "Loss: \n",
      "98110.4540786\n",
      "Loss: \n",
      "98010.1049961\n",
      "Loss: \n",
      "97973.8369181\n",
      "Loss: \n",
      "97967.5228354\n",
      "Loss: \n",
      "97910.172076\n",
      "Loss: \n",
      "97899.7423281\n",
      "Loss: \n",
      "97864.0721738\n",
      "Loss: \n",
      "97879.3115509\n",
      "Loss: \n",
      "97798.9571723\n",
      "Loss: \n",
      "97770.3811424\n",
      "Loss: \n",
      "97757.8818715\n",
      "Loss: \n",
      "97729.6102866\n",
      "Loss: \n",
      "97749.1930466\n",
      "Loss: \n",
      "97663.924074\n",
      "Loss: \n",
      "97629.9220725\n",
      "Loss: \n",
      "97613.835455\n",
      "Loss: \n",
      "97573.6963229\n",
      "Loss: \n",
      "97578.5446095\n",
      "Loss: \n",
      "97499.1138406\n",
      "Loss: \n",
      "97464.6757889\n",
      "Loss: \n",
      "97436.1087544\n",
      "Loss: \n",
      "97420.8928183\n",
      "Loss: \n",
      "97440.133483\n",
      "Loss: \n",
      "97356.0922993\n",
      "Loss: \n",
      "97326.9395567\n",
      "Loss: \n",
      "97319.1170525\n",
      "Loss: \n",
      "97276.9503666\n",
      "Loss: \n",
      "97279.7237196\n",
      "Loss: \n",
      "97214.3935547\n",
      "Loss: \n",
      "97183.4843007\n",
      "Loss: \n",
      "97144.0011934\n",
      "Loss: \n",
      "97066.1884221\n",
      "Loss: \n",
      "96985.752064\n",
      "Loss: \n",
      "96957.8694237\n",
      "Loss: \n",
      "96937.0256575\n",
      "Loss: \n",
      "96928.0622537\n",
      "Loss: \n",
      "96951.4655629\n",
      "Loss: \n",
      "96868.4689444\n",
      "Loss: \n",
      "96837.1727637\n",
      "Loss: \n",
      "96826.9170896\n",
      "Loss: \n",
      "96786.2356019\n",
      "Loss: \n",
      "96788.1095916\n",
      "Loss: \n",
      "96722.3676597\n",
      "Loss: \n",
      "96693.8261242\n",
      "Loss: \n",
      "96672.9444528\n",
      "Loss: \n",
      "96678.3234091\n",
      "Loss: \n",
      "96602.5631452\n",
      "Loss: \n",
      "96568.0596732\n",
      "Loss: \n",
      "96537.9848962\n",
      "Loss: \n",
      "96523.7153963\n",
      "Loss: \n",
      "96500.1685074\n",
      "Loss: \n",
      "96522.3033966\n",
      "Loss: \n",
      "96442.0282636\n",
      "Loss: \n",
      "96415.826388\n",
      "Loss: \n",
      "96408.9145643\n",
      "Loss: \n",
      "96378.7171404\n",
      "Loss: \n",
      "96387.5301886\n",
      "Loss: \n",
      "96330.1467197\n",
      "Loss: \n",
      "96304.3762509\n",
      "Loss: \n",
      "96290.4920225\n",
      "Loss: \n",
      "96295.3017286\n",
      "Loss: \n",
      "96250.3178278\n",
      "Loss: \n",
      "96246.7787376\n",
      "Loss: \n",
      "96214.6673231\n",
      "Loss: \n",
      "96221.9803243\n",
      "Loss: \n",
      "96164.7814401\n",
      "Loss: \n",
      "96141.1843968\n",
      "Loss: \n",
      "96129.9249968\n",
      "Loss: \n",
      "96139.5072892\n",
      "Loss: \n",
      "96083.782611\n",
      "Loss: \n",
      "96064.5334414\n",
      "Loss: \n",
      "96059.1285657\n",
      "Loss: \n",
      "96078.9798652\n",
      "Loss: \n",
      "96006.5530747\n",
      "Loss: \n",
      "95980.9074809\n",
      "Loss: \n",
      "95972.6254381\n",
      "Loss: \n",
      "95949.8671564\n",
      "Loss: \n",
      "95965.1648382\n",
      "Loss: \n",
      "95896.1975228\n",
      "Loss: \n",
      "95874.2458935\n",
      "Loss: \n",
      "95855.6890208\n",
      "Loss: \n",
      "95846.1189982\n",
      "Loss: \n",
      "95852.9553077\n",
      "Loss: \n",
      "95747.6337949\n",
      "Loss: \n",
      "95674.0962468\n",
      "Loss: \n",
      "95660.0395879\n",
      "Loss: \n",
      "95644.6757482\n",
      "Loss: \n",
      "95662.9984218\n",
      "Loss: \n",
      "95592.2578502\n",
      "Loss: \n",
      "95572.8454997\n",
      "Loss: \n",
      "95561.5074424\n",
      "Loss: \n",
      "95551.9076435\n",
      "Loss: \n",
      "95567.9588461\n",
      "Loss: \n",
      "95501.2987705\n",
      "Loss: \n",
      "95475.990353\n",
      "Loss: \n",
      "95463.9485266\n",
      "Loss: \n",
      "95449.2096635\n",
      "Loss: \n",
      "95464.891306\n",
      "Loss: \n",
      "95397.865679\n",
      "Loss: \n",
      "95377.9190357\n",
      "Loss: \n",
      "95361.1319472\n",
      "Loss: \n",
      "95354.7839839\n",
      "Loss: \n",
      "95368.2130855\n",
      "Loss: \n",
      "95304.0537872\n",
      "Loss: \n",
      "95278.2911091\n",
      "Loss: \n",
      "95260.8240989\n",
      "Loss: \n",
      "95243.6905836\n",
      "Loss: \n",
      "95247.8735556\n",
      "Loss: \n",
      "95201.7826088\n",
      "Loss: \n",
      "95197.1232408\n",
      "Loss: \n",
      "95161.1293117\n",
      "Loss: \n",
      "95161.124092\n",
      "Loss: \n",
      "95105.8843317\n",
      "Loss: \n",
      "95077.3693684\n",
      "Loss: \n",
      "95023.0117972\n",
      "Loss: \n",
      "95020.0128092\n",
      "Loss: \n",
      "94956.6729266\n",
      "Loss: \n",
      "94930.8430951\n",
      "Loss: \n",
      "94879.674608\n",
      "Loss: \n",
      "94865.271601\n",
      "Loss: \n",
      "94856.765686\n",
      "Loss: \n",
      "94881.5146472\n",
      "Loss: \n",
      "94867.7319176\n",
      "Loss: \n",
      "94790.4442381\n",
      "Loss: \n",
      "94775.2249363\n",
      "Loss: \n",
      "94781.7515102\n",
      "Loss: \n",
      "94748.8571983\n",
      "Loss: \n",
      "94767.7910461\n",
      "Loss: \n",
      "94703.8564281\n",
      "Loss: \n",
      "94697.7517905\n",
      "Loss: \n",
      "94679.8606982\n",
      "Loss: \n",
      "94720.2300274\n",
      "Loss: \n",
      "94627.2795007\n",
      "Loss: \n",
      "94604.3131919\n",
      "Loss: \n",
      "94595.2218773\n",
      "Loss: \n",
      "94616.9886445\n",
      "Loss: \n",
      "94590.2166226\n",
      "Loss: \n",
      "94644.6863138\n",
      "Loss: \n",
      "94556.6153376\n",
      "Loss: \n",
      "94537.3384491\n",
      "Loss: \n",
      "94497.8193249\n",
      "Loss: \n",
      "94505.8423768\n",
      "Loss: \n",
      "94549.8935729\n",
      "Loss: \n",
      "94491.4176862\n",
      "Loss: \n",
      "94421.4149278\n",
      "Loss: \n",
      "94400.8003537\n",
      "Loss: \n",
      "94395.0476249\n",
      "Loss: \n",
      "94434.7575427\n",
      "Loss: \n",
      "94362.4107782\n",
      "Loss: \n",
      "94385.0895316\n",
      "Loss: \n",
      "94321.9090975\n",
      "Loss: \n",
      "94322.5557299\n",
      "Loss: \n",
      "94308.4399757\n",
      "Loss: \n",
      "94362.6747542\n",
      "Loss: \n",
      "94261.0465985\n",
      "Loss: \n",
      "94239.3135221\n",
      "Loss: \n",
      "94230.9365832\n",
      "Loss: \n",
      "94248.707547\n",
      "Loss: \n",
      "94231.8575656\n",
      "Loss: \n",
      "94290.6665625\n",
      "Loss: \n",
      "94203.0480745\n",
      "Loss: \n",
      "94189.4458542\n",
      "Loss: \n",
      "94143.4346463\n",
      "Loss: \n",
      "94154.7631375\n",
      "Loss: \n",
      "94204.0406425\n",
      "Loss: \n",
      "94158.7286834\n",
      "Loss: \n",
      "94082.8470586\n",
      "Loss: \n",
      "94067.2510925\n",
      "Loss: \n",
      "94076.377657\n",
      "Loss: \n",
      "94119.559863\n",
      "Loss: \n",
      "94046.2588735\n",
      "Loss: \n",
      "94012.2930625\n",
      "Loss: \n",
      "94005.1697197\n",
      "Loss: \n",
      "94038.2980005\n",
      "Loss: \n",
      "94034.8287466\n",
      "Loss: \n",
      "93959.2729034\n",
      "Loss: \n",
      "93939.4857709\n",
      "Loss: \n",
      "93956.8575593\n",
      "Loss: \n",
      "93942.4321557\n",
      "Loss: \n",
      "94003.2993081\n",
      "Loss: \n",
      "93902.5994412\n",
      "Loss: \n",
      "93871.0964637\n",
      "Loss: \n",
      "93861.5903495\n",
      "Loss: \n",
      "93896.7174226\n",
      "Loss: \n",
      "93903.7534413\n",
      "Loss: \n",
      "93829.3714651\n",
      "Loss: \n",
      "93796.4184332\n",
      "Loss: \n",
      "93796.6787676\n",
      "Loss: \n",
      "93780.0633748\n",
      "Loss: \n",
      "93828.8059773\n",
      "Loss: \n",
      "93743.2141645\n",
      "Loss: \n",
      "93734.9797373\n",
      "Loss: \n",
      "93724.4749899\n",
      "Loss: \n",
      "93746.7813035\n",
      "Loss: \n",
      "93772.977845\n",
      "Loss: \n",
      "93706.2376879\n",
      "Loss: \n",
      "93655.511422\n",
      "Loss: \n",
      "93648.9624803\n",
      "Loss: \n",
      "93617.9960778\n",
      "Loss: \n",
      "93636.4393406\n",
      "Loss: \n",
      "93613.3773131\n",
      "Loss: \n",
      "93665.640065\n",
      "Loss: \n",
      "93569.433355\n",
      "Loss: \n",
      "93553.3393825\n",
      "Loss: \n",
      "93571.7252701\n",
      "Loss: \n",
      "93557.0197859\n",
      "Loss: \n",
      "93554.892321\n",
      "Loss: \n",
      "93483.1934461\n",
      "Loss: \n",
      "93465.9633972\n",
      "Loss: \n",
      "93468.3022812\n",
      "Loss: \n",
      "93430.4913848\n",
      "Loss: \n",
      "93423.4072645\n",
      "Loss: \n",
      "93409.5744681\n",
      "Loss: \n",
      "93440.388645\n",
      "Loss: \n",
      "93410.5956752\n",
      "Loss: \n",
      "93473.826577\n",
      "Loss: \n",
      "93381.7488217\n",
      "Loss: \n",
      "93342.8584543\n",
      "Loss: \n",
      "93310.334947\n",
      "Loss: \n",
      "93345.5142621\n",
      "Loss: \n",
      "93404.0164951\n",
      "Loss: \n",
      "93320.3464385\n",
      "Loss: \n",
      "93255.826817\n",
      "Loss: \n",
      "93240.9351142\n",
      "Loss: \n",
      "93218.3257343\n",
      "Loss: \n",
      "93242.2851793\n",
      "Loss: \n",
      "93288.1274717\n",
      "Loss: \n",
      "93208.9847555\n",
      "Loss: \n",
      "93172.4652015\n",
      "Loss: \n",
      "93192.1769666\n",
      "Loss: \n",
      "93194.7186356\n",
      "Loss: \n",
      "93265.675082\n",
      "Loss: \n",
      "93172.8722038\n",
      "Loss: \n",
      "93142.3982264\n",
      "Loss: \n",
      "93098.2211967\n",
      "Loss: \n",
      "93098.9453398\n",
      "Loss: \n",
      "93110.9215123\n",
      "Loss: \n",
      "93182.7129098\n",
      "Loss: \n",
      "93087.4205132\n",
      "Loss: \n",
      "93048.6158516\n",
      "Loss: \n",
      "93017.1193357\n",
      "Loss: \n",
      "93015.6718226\n",
      "Loss: \n",
      "92992.2164248\n",
      "Loss: \n",
      "93033.1974642\n",
      "Loss: \n",
      "92972.0775943\n",
      "Loss: \n",
      "92992.2498562\n",
      "Loss: \n",
      "92983.385111\n",
      "Loss: \n",
      "93049.1659382\n",
      "Loss: \n",
      "92968.9120672\n",
      "Loss: \n",
      "92935.2447923\n",
      "Loss: \n",
      "92892.9012644\n",
      "Loss: \n",
      "92891.5334759\n",
      "Loss: \n",
      "92908.6534863\n",
      "Loss: \n",
      "92982.3142729\n",
      "Loss: \n",
      "92889.4626898\n",
      "Loss: \n",
      "92849.5925582\n",
      "Loss: \n",
      "92819.3873998\n",
      "Loss: \n",
      "92817.3458087\n",
      "Loss: \n",
      "92799.2102701\n",
      "Loss: \n",
      "92847.7057383\n",
      "Loss: \n",
      "92772.9547629\n",
      "Loss: \n",
      "92768.4334082\n",
      "Loss: \n",
      "92755.086235\n",
      "Loss: \n",
      "92809.6693854\n",
      "Loss: \n",
      "92725.1233228\n",
      "Loss: \n",
      "92715.64126\n",
      "Loss: \n",
      "92691.7863018\n",
      "Loss: \n",
      "92690.7398422\n",
      "Loss: \n",
      "92675.9001875\n",
      "Loss: \n",
      "92712.5233572\n",
      "Loss: \n",
      "92775.6081697\n",
      "Loss: \n",
      "92698.5636355\n",
      "Loss: \n",
      "92637.043242\n",
      "Loss: \n",
      "92621.5847328\n",
      "Loss: \n",
      "92601.9135568\n",
      "Loss: \n",
      "92604.3356378\n",
      "Loss: \n",
      "92597.2600909\n",
      "Loss: \n",
      "92659.5301925\n",
      "Loss: \n",
      "92570.0978955\n",
      "Loss: \n",
      "92564.6202132\n",
      "Loss: \n",
      "92580.1026039\n",
      "Loss: \n",
      "92565.2947703\n",
      "Loss: \n",
      "92610.2776774\n",
      "Loss: \n",
      "92540.8049458\n",
      "Loss: \n",
      "92502.1450253\n",
      "Loss: \n",
      "92522.0490481\n",
      "Loss: \n",
      "92502.9908165\n",
      "Loss: \n",
      "92564.5514217\n",
      "Loss: \n",
      "92481.1951643\n",
      "Loss: \n",
      "92453.9823246\n",
      "Loss: \n",
      "92441.3905504\n",
      "Loss: \n",
      "92476.5198839\n",
      "Loss: \n",
      "92521.4635419\n",
      "Loss: \n",
      "92453.9538376\n",
      "Loss: \n",
      "92398.7475431\n",
      "Loss: \n",
      "92380.3438244\n",
      "Loss: \n",
      "92355.2320346\n",
      "Loss: \n",
      "92373.0555358\n",
      "Loss: \n",
      "92417.7053593\n",
      "Loss: \n",
      "92346.7014424\n",
      "Loss: \n",
      "92318.1769116\n",
      "Loss: \n",
      "92347.7173956\n",
      "Loss: \n",
      "92306.9973298\n",
      "Loss: \n",
      "92361.3619666\n",
      "Loss: \n",
      "92276.3669323\n",
      "Loss: \n",
      "92271.377207\n",
      "Loss: \n",
      "92294.7379397\n",
      "Loss: \n",
      "92243.9353954\n",
      "Loss: \n",
      "92246.2931457\n",
      "Loss: \n",
      "92237.507762\n",
      "Loss: \n",
      "92284.0933338\n",
      "Loss: \n",
      "92220.3927073\n",
      "Loss: \n",
      "92171.8995904\n",
      "Loss: \n",
      "92174.9390353\n",
      "Loss: \n",
      "92184.1168538\n",
      "Loss: \n",
      "92240.8953949\n",
      "Loss: \n",
      "92158.5041017\n",
      "Loss: \n",
      "92118.1017901\n",
      "Loss: \n",
      "92083.2592319\n",
      "Loss: \n",
      "92077.9304788\n",
      "Loss: \n",
      "92081.8106853\n",
      "Loss: \n",
      "92091.0610629\n",
      "Loss: \n",
      "92143.4625884\n",
      "Loss: \n",
      "92075.9417289\n",
      "Loss: \n",
      "92015.0912153\n",
      "Loss: \n",
      "91992.8814128\n",
      "Loss: \n",
      "91971.4170916\n",
      "Loss: \n",
      "91974.66455\n",
      "Loss: \n",
      "91989.1649125\n",
      "Loss: \n",
      "91981.2319552\n",
      "Loss: \n",
      "92033.201516\n",
      "Loss: \n",
      "91959.5387351\n",
      "Loss: \n",
      "91913.7194973\n",
      "Loss: \n",
      "91927.8513062\n",
      "Loss: \n",
      "91924.1042855\n",
      "Loss: \n",
      "91983.7649786\n",
      "Loss: \n",
      "91904.6947592\n",
      "Loss: \n",
      "91868.1025775\n",
      "Loss: \n",
      "91839.5021499\n",
      "Loss: \n",
      "91848.3964084\n",
      "Loss: \n",
      "91887.7262599\n",
      "Loss: \n",
      "91807.6630223\n",
      "Loss: \n",
      "91779.5247627\n",
      "Loss: \n",
      "91792.655852\n",
      "Loss: \n",
      "91799.175443\n",
      "Loss: \n",
      "91860.9087253\n",
      "Loss: \n",
      "91757.6842261\n",
      "Loss: \n",
      "91702.2181761\n",
      "Loss: \n",
      "91664.3176944\n",
      "Loss: \n",
      "91653.6085836\n",
      "Loss: \n",
      "91654.3411467\n",
      "Loss: \n",
      "91687.3494324\n",
      "Loss: \n",
      "91751.3907276\n",
      "Loss: \n",
      "91659.6927003\n",
      "Loss: \n",
      "91594.8370231\n",
      "Loss: \n",
      "91570.2429673\n",
      "Loss: \n",
      "91549.3902242\n",
      "Loss: \n",
      "91569.9969328\n",
      "Loss: \n",
      "91624.7345594\n",
      "Loss: \n",
      "91542.090305\n",
      "Loss: \n",
      "91511.5873542\n",
      "Loss: \n",
      "91537.9653521\n",
      "Loss: \n",
      "91498.723755\n",
      "Loss: \n",
      "91557.9674982\n",
      "Loss: \n",
      "91470.5196203\n",
      "Loss: \n",
      "91459.8758844\n",
      "Loss: \n",
      "91482.0908861\n",
      "Loss: \n",
      "91445.372797\n",
      "Loss: \n",
      "91482.5865358\n",
      "Loss: \n",
      "91407.8371966\n",
      "Loss: \n",
      "91383.9958056\n",
      "Loss: \n",
      "91402.1144734\n",
      "Loss: \n",
      "91426.7829229\n",
      "Loss: \n",
      "91500.5503915\n",
      "Loss: \n",
      "91412.1724422\n",
      "Loss: \n",
      "91366.1407332\n",
      "Loss: \n",
      "91333.6925725\n",
      "Loss: \n",
      "91326.4363527\n",
      "Loss: \n",
      "91336.269832\n",
      "Loss: \n",
      "91407.9633308\n",
      "Loss: \n",
      "91318.7059987\n",
      "Loss: \n",
      "91297.6647512\n",
      "Loss: \n",
      "91302.699392\n",
      "Loss: \n",
      "91324.6613657\n",
      "Loss: \n",
      "91376.1088181\n",
      "Loss: \n",
      "91308.232142\n",
      "Loss: \n",
      "91250.9359701\n",
      "Loss: \n",
      "91227.4548371\n",
      "Loss: \n",
      "91206.1740787\n",
      "Loss: \n",
      "91205.5312797\n",
      "Loss: \n",
      "91210.4342824\n",
      "Loss: \n",
      "91284.3794403\n",
      "Loss: \n",
      "91190.5098928\n",
      "Loss: \n",
      "91186.9505531\n",
      "Loss: \n",
      "91232.1629831\n",
      "Loss: \n",
      "91153.942003\n",
      "Loss: \n",
      "91132.6762722\n",
      "Loss: \n",
      "91153.9695997\n",
      "Loss: \n",
      "91220.8691295\n",
      "Loss: \n",
      "91140.1114896\n",
      "Loss: \n",
      "91112.3274478\n",
      "Loss: \n",
      "91146.6778329\n",
      "Loss: \n",
      "91094.8169711\n",
      "Loss: \n",
      "91149.1537414\n",
      "Loss: \n",
      "91062.4834821\n",
      "Loss: \n",
      "91051.3794557\n",
      "Loss: \n",
      "91058.7595033\n",
      "Loss: \n",
      "91109.4326051\n",
      "Loss: \n",
      "91174.6195355\n",
      "Loss: \n",
      "91093.1283506\n",
      "Loss: \n",
      "91029.3910721\n",
      "Loss: \n",
      "91004.8244088\n",
      "Loss: \n",
      "90981.495305\n",
      "Loss: \n",
      "91005.1076246\n",
      "Loss: \n",
      "91064.1830527\n",
      "Loss: \n",
      "90980.271197\n",
      "Loss: \n",
      "90946.5439751\n",
      "Loss: \n",
      "90952.8559047\n",
      "Loss: \n",
      "90972.6818404\n",
      "Loss: \n",
      "91034.9188146\n",
      "Loss: \n",
      "90948.0810771\n",
      "Loss: \n",
      "90910.5234221\n",
      "Loss: \n",
      "90877.7685847\n",
      "Loss: \n",
      "90882.1350762\n",
      "Loss: \n",
      "90925.3537362\n",
      "Loss: \n",
      "90850.2345226\n",
      "Loss: \n",
      "90834.6572925\n",
      "Loss: \n",
      "90870.2108771\n",
      "Loss: \n",
      "90938.4057151\n",
      "Loss: \n",
      "90857.6698965\n",
      "Loss: \n",
      "90803.4076091\n",
      "Loss: \n",
      "90783.2061112\n",
      "Loss: \n",
      "90785.3371068\n",
      "Loss: \n",
      "90846.7875042\n",
      "Loss: \n",
      "90750.2779764\n",
      "Loss: \n",
      "90734.438886\n",
      "Loss: \n",
      "90732.5684723\n",
      "Loss: \n",
      "90783.9762315\n",
      "Loss: \n",
      "90852.2887242\n",
      "Loss: \n",
      "90764.3481031\n",
      "Loss: \n",
      "90699.1378537\n",
      "Loss: \n",
      "90671.1937539\n",
      "Loss: \n",
      "90646.1346082\n",
      "Loss: \n",
      "90637.127289\n",
      "Loss: \n",
      "90619.5596813\n",
      "Loss: \n",
      "90618.7069055\n",
      "Loss: \n",
      "90644.7252506\n",
      "Loss: \n",
      "90653.427703\n",
      "Loss: \n",
      "90725.8819408\n",
      "Loss: \n",
      "90640.5137907\n",
      "Loss: \n",
      "90576.2320293\n",
      "Loss: \n",
      "90550.1710429\n",
      "Loss: \n",
      "90532.430143\n",
      "Loss: \n",
      "90527.2903369\n",
      "Loss: \n",
      "90520.4885664\n",
      "Loss: \n",
      "90565.0572239\n",
      "Loss: \n",
      "90520.0674541\n",
      "Loss: \n",
      "90577.8076444\n",
      "Loss: \n",
      "90478.8340631\n",
      "Loss: \n",
      "90481.3381772\n",
      "Loss: \n",
      "90522.1984614\n",
      "Loss: \n",
      "90459.3913792\n",
      "Loss: \n",
      "90449.2094683\n",
      "Loss: \n",
      "90492.1888127\n",
      "Loss: \n",
      "90548.4833086\n",
      "Loss: \n",
      "90475.453588\n",
      "Loss: \n",
      "90410.9446142\n",
      "Loss: \n",
      "90380.8352059\n",
      "Loss: \n",
      "90361.8243267\n",
      "Loss: \n",
      "90380.0824222\n",
      "Loss: \n",
      "90392.2902485\n",
      "Loss: \n",
      "90464.9035245\n",
      "Loss: \n",
      "90373.4223256\n",
      "Loss: \n",
      "90324.3268604\n",
      "Loss: \n",
      "90291.4412186\n",
      "Loss: \n",
      "90281.9691659\n",
      "Loss: \n",
      "90286.6066773\n",
      "Loss: \n",
      "90336.9942459\n",
      "Loss: \n",
      "90408.2376534\n",
      "Loss: \n",
      "90317.8933715\n",
      "Loss: \n",
      "90260.943132\n",
      "Loss: \n",
      "90233.3084193\n",
      "Loss: \n",
      "90206.9624777\n",
      "Loss: \n",
      "90198.8242859\n",
      "Loss: \n",
      "90190.5116772\n",
      "Loss: \n",
      "90233.0842563\n",
      "Loss: \n",
      "90211.5806824\n",
      "Loss: \n",
      "90290.1519075\n",
      "Loss: \n",
      "90176.4631933\n",
      "Loss: \n",
      "90131.4162408\n",
      "Loss: \n",
      "90119.3245381\n",
      "Loss: \n",
      "90153.0644787\n",
      "Loss: \n",
      "90223.6234158\n",
      "Loss: \n",
      "90098.175908\n",
      "Loss: \n",
      "90063.8405216\n",
      "Loss: \n",
      "90035.9511218\n",
      "Loss: \n",
      "90011.5835836\n",
      "Loss: \n",
      "90014.7355888\n",
      "Loss: \n",
      "90062.1147254\n",
      "Loss: \n",
      "90141.2187457\n",
      "Loss: \n",
      "90033.6755653\n",
      "Loss: \n",
      "89995.2219195\n",
      "Loss: \n",
      "89961.9750396\n",
      "Loss: \n",
      "89961.0698235\n",
      "Loss: \n",
      "90005.4057882\n",
      "Loss: \n",
      "89954.3408302\n",
      "Loss: \n",
      "89983.4150962\n",
      "Loss: \n",
      "89940.2683833\n",
      "Loss: \n",
      "89988.6568018\n",
      "Loss: \n",
      "89910.6851859\n",
      "Loss: \n",
      "89879.3857119\n",
      "Loss: \n",
      "89877.5464931\n",
      "Loss: \n",
      "89902.8430628\n",
      "Loss: \n",
      "89994.4405444\n",
      "Loss: \n",
      "89893.3130564\n",
      "Loss: \n",
      "89859.1324773\n",
      "Loss: \n",
      "89849.1910884\n",
      "Loss: \n",
      "89901.8546081\n",
      "Loss: \n",
      "89969.8122693\n",
      "Loss: \n",
      "89877.0633264\n",
      "Loss: \n",
      "89827.9225781\n",
      "Loss: \n",
      "89799.4118324\n",
      "Loss: \n",
      "89783.69542\n",
      "Loss: \n",
      "89819.0893478\n",
      "Loss: \n",
      "89814.4594202\n",
      "Loss: \n",
      "89888.973794\n",
      "Loss: \n",
      "89789.4705861\n",
      "Loss: \n",
      "89751.2495749\n",
      "Loss: \n",
      "89720.0691583\n",
      "Loss: \n",
      "89727.1207456\n",
      "Loss: \n",
      "89779.1573628\n",
      "Loss: \n",
      "89693.0605761\n",
      "Loss: \n",
      "89662.3641269\n",
      "Loss: \n",
      "89700.0120333\n",
      "Loss: \n",
      "89781.6379992\n",
      "Loss: \n",
      "89650.6965135\n",
      "Loss: \n",
      "89596.4571676\n",
      "Loss: \n",
      "89557.3952982\n",
      "Loss: \n",
      "89565.4651227\n",
      "Loss: \n",
      "89655.879375\n",
      "Loss: \n",
      "89519.7783554\n",
      "Loss: \n",
      "89479.8693094\n",
      "Loss: \n",
      "89454.5703582\n",
      "Loss: \n",
      "89450.8201165\n",
      "Loss: \n",
      "89475.4818189\n",
      "Loss: \n",
      "89535.8107093\n",
      "Loss: \n",
      "89625.9097544\n",
      "Loss: \n",
      "89489.5416893\n",
      "Loss: \n",
      "89423.9765293\n",
      "Loss: \n",
      "89390.1199956\n",
      "Loss: \n",
      "89352.6710548\n",
      "Loss: \n",
      "89351.5976921\n",
      "Loss: \n",
      "89401.2236251\n",
      "Loss: \n",
      "89342.80092\n",
      "Loss: \n",
      "89366.3241622\n",
      "Loss: \n",
      "89343.8057277\n",
      "Loss: \n",
      "89402.9598157\n",
      "Loss: \n",
      "89320.0415065\n",
      "Loss: \n",
      "89281.6814221\n",
      "Loss: \n",
      "89268.8285829\n",
      "Loss: \n",
      "89301.2006136\n",
      "Loss: \n",
      "89384.5131846\n",
      "Loss: \n",
      "89272.9506558\n",
      "Loss: \n",
      "89240.6909833\n",
      "Loss: \n",
      "89209.0022405\n",
      "Loss: \n",
      "89232.5176124\n",
      "Loss: \n",
      "89305.3980867\n",
      "Loss: \n",
      "89202.9068992\n",
      "Loss: \n",
      "89162.3267499\n",
      "Loss: \n",
      "89150.6673374\n",
      "Loss: \n",
      "89159.3774601\n",
      "Loss: \n",
      "89240.7602088\n",
      "Loss: \n",
      "89135.2783006\n",
      "Loss: \n",
      "89113.7828664\n",
      "Loss: \n",
      "89102.4921949\n",
      "Loss: \n",
      "89107.4441794\n",
      "Loss: \n",
      "89159.6586133\n",
      "Loss: \n",
      "89268.2770759\n",
      "Loss: \n",
      "89149.3008204\n",
      "Loss: \n",
      "89100.2622622\n",
      "Loss: \n",
      "89065.0215269\n",
      "Loss: \n",
      "89059.695158\n",
      "Loss: \n",
      "89084.1152213\n",
      "Loss: \n",
      "89133.2071051\n",
      "Loss: \n",
      "89222.9408529\n",
      "Loss: \n",
      "89108.6778276\n",
      "Loss: \n",
      "89054.0777638\n",
      "Loss: \n",
      "89025.5222003\n",
      "Loss: \n",
      "89006.3705991\n",
      "Loss: \n",
      "89019.2700677\n",
      "Loss: \n",
      "89071.5835938\n",
      "Loss: \n",
      "89156.6933503\n",
      "Loss: \n",
      "89039.1648735\n",
      "Loss: \n",
      "89003.0151653\n",
      "Loss: \n",
      "88965.3987153\n",
      "Loss: \n",
      "88969.3995595\n",
      "Loss: \n",
      "89022.3398948\n",
      "Loss: \n",
      "88974.254639\n",
      "Loss: \n",
      "89001.7323587\n",
      "Loss: \n",
      "88974.3803093\n",
      "Loss: \n",
      "89022.8357331\n",
      "Loss: \n",
      "88937.7886009\n",
      "Loss: \n",
      "88888.5855979\n",
      "Loss: \n",
      "88862.9675914\n",
      "Loss: \n",
      "88851.5867995\n",
      "Loss: \n",
      "88943.6019523\n",
      "Loss: \n",
      "89080.610642\n",
      "Loss: \n",
      "88902.8691137\n",
      "Loss: \n",
      "88839.4401379\n",
      "Loss: \n",
      "88811.7212111\n",
      "Loss: \n",
      "88791.954817\n",
      "Loss: \n",
      "88822.080127\n",
      "Loss: \n",
      "88861.8636447\n",
      "Loss: \n",
      "88953.2980145\n",
      "Loss: \n",
      "88814.2159372\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "train_M, prediction_M = train_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.78113737,  3.7953809 ,  2.55474097, ...,  4.12876146,\n",
       "         4.30455564,  3.54276885],\n",
       "       [ 3.78113737,  3.7953809 ,  2.55474097, ...,  4.12876146,\n",
       "         4.30455564,  3.54276885],\n",
       "       [ 3.78113737,  3.7953809 ,  2.55474097, ...,  4.12876146,\n",
       "         4.30455564,  3.54276885],\n",
       "       ..., \n",
       "       [ 1.82912791,  1.86031733,  1.32736765, ...,  2.82363721,\n",
       "         2.25867506,  1.68323696],\n",
       "       [ 1.35908037,  0.0968063 ,  1.00196212, ...,  3.82875147,\n",
       "         0.50932801,  1.11054272],\n",
       "       [ 2.3829312 ,  1.94248052,  2.18044253, ...,  3.91817685,\n",
       "         3.0652761 ,  1.9540968 ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  4.,  0., ...,  5.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  5.],\n",
       "       [ 4.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10f185128>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.tile(np.array([2,1]), 3) # stands for repeat\n",
    "# t = np.tile(np.array([2,1]), [10, 1])\n",
    "# t2 = t.copy()\n",
    "# t2[t == 1] = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = np.array([[2,1], [10, 1]])#2,2\n",
    "# b = np.array([[3,4],[4, 4])#2,1\n",
    "# a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
