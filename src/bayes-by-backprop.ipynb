{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AdrianHsu/anaconda/envs/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams\n",
    "from lasagne.updates import adam\n",
    "#from lasagne.utils import collect_shared_vars\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd = RandomStreams(seed=123)\n",
    "gpu_rnd = MRG_RandomStreams(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_shared_vars(expressions):\n",
    "   \"\"\"Returns all shared variables the given expression(s) depend on.\n",
    "      Parameters\n",
    "      ----------\n",
    "      expressions : Theano expression or iterable of Theano expressions\n",
    "      The expressions to collect shared variables from.\n",
    "      Returns\n",
    "      -------\n",
    "      list of Theano shared variables\n",
    "      All shared variables the given expression(s) depend on, in fixed order\n",
    "      (as found by a left-recursive depth-first search). If some expressions\n",
    "      are shared variables themselves, they are included in the result.\n",
    "      \"\"\"\n",
    "   # wrap single expression in list\n",
    "   if isinstance(expressions, theano.Variable):\n",
    "      expressions = [expressions]\n",
    "   # return list of all shared variables\n",
    "   return [v for v in theano.gof.graph.inputs(reversed(expressions))\n",
    "      if isinstance(v, theano.compile.SharedVariable)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonlinearity(x):\n",
    "    return T.nnet.relu(x)\n",
    "def log_gaussian(x, mu, sigma):\n",
    "    return -0.5 * np.log(2 * np.pi) - T.log(T.abs_(sigma)) - (x - mu) ** 2 / (2 * sigma ** 2)\n",
    "def log_gaussian_logsigma(x, mu, logsigma):\n",
    "    return -0.5 * np.log(2 * np.pi) - logsigma / 2. - (x - mu) ** 2 / (2. * T.exp(logsigma) **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _shared_dataset(data_xy, borrow=True):\n",
    "    data_x, data_y = data_xy\n",
    "    shared_x = theano.shared(np.asarray(data_x, dtype=theano.config.floatX), borrow=borrow)\n",
    "    shared_y = theano.shared(np.asarray(data_y, dtype=theano.config.floatX), borrow=borrow)\n",
    "    return shared_x, shared_y\n",
    "def init(shape):\n",
    "    return np.asarray(\n",
    "        np.random.normal(0, 0.05, size=shape),\n",
    "        dtype=theano.config.floatX\n",
    "    )\n",
    "def get_random(shape, avg, std):\n",
    "    return gpu_rnd.normal(shape, avg=avg, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cost 7.92116829976 Accuracy 0.808\n",
      "epoch 1 cost -74.2470156024 Accuracy 0.876\n",
      "epoch 2 cost -89.9187408326 Accuracy 0.904\n",
      "epoch 3 cost -97.7810509248 Accuracy 0.884\n",
      "epoch 4 cost -101.610847742 Accuracy 0.916\n",
      "epoch 5 cost -105.272886592 Accuracy 0.912\n",
      "epoch 6 cost -108.411979264 Accuracy 0.92\n",
      "epoch 7 cost -110.517581453 Accuracy 0.924\n",
      "epoch 8 cost -112.679266811 Accuracy 0.932\n",
      "epoch 9 cost -114.33643211 Accuracy 0.928\n",
      "epoch 10 cost -115.755182285 Accuracy 0.948\n",
      "epoch 11 cost -117.211421147 Accuracy 0.94\n",
      "epoch 12 cost -118.673764123 Accuracy 0.936\n",
      "epoch 13 cost -119.160909933 Accuracy 0.936\n",
      "epoch 14 cost -120.317832293 Accuracy 0.944\n",
      "epoch 15 cost -121.392126593 Accuracy 0.956\n",
      "epoch 16 cost -122.364807975 Accuracy 0.944\n",
      "epoch 17 cost -123.409712092 Accuracy 0.96\n",
      "epoch 18 cost -124.163917721 Accuracy 0.932\n",
      "epoch 19 cost -124.426873819 Accuracy 0.948\n",
      "epoch 20 cost -124.74436431 Accuracy 0.944\n",
      "epoch 21 cost -125.252377591 Accuracy 0.952\n",
      "epoch 22 cost -125.600265255 Accuracy 0.948\n",
      "epoch 23 cost -126.182487746 Accuracy 0.944\n",
      "epoch 24 cost -126.596785729 Accuracy 0.956\n",
      "epoch 25 cost -127.010441983 Accuracy 0.956\n",
      "epoch 26 cost -127.470931215 Accuracy 0.94\n",
      "epoch 27 cost -127.641345038 Accuracy 0.952\n",
      "epoch 28 cost -127.839556273 Accuracy 0.96\n",
      "epoch 29 cost -128.709805713 Accuracy 0.944\n",
      "epoch 30 cost -128.523255381 Accuracy 0.96\n",
      "epoch 31 cost -128.908872818 Accuracy 0.948\n",
      "epoch 32 cost -129.13247321 Accuracy 0.94\n",
      "epoch 33 cost -129.347375677 Accuracy 0.964\n",
      "epoch 34 cost -130.069605075 Accuracy 0.948\n",
      "epoch 35 cost -130.378519729 Accuracy 0.952\n",
      "epoch 36 cost -130.325739624 Accuracy 0.952\n",
      "epoch 37 cost -130.84301928 Accuracy 0.96\n",
      "epoch 38 cost -131.343006333 Accuracy 0.948\n",
      "epoch 39 cost -131.080788248 Accuracy 0.956\n",
      "epoch 40 cost -131.318040572 Accuracy 0.936\n",
      "epoch 41 cost -131.57865548 Accuracy 0.944\n",
      "epoch 42 cost -131.790169526 Accuracy 0.952\n",
      "epoch 43 cost -131.335924532 Accuracy 0.944\n",
      "epoch 44 cost -132.363001665 Accuracy 0.936\n",
      "epoch 45 cost -132.502005282 Accuracy 0.956\n",
      "epoch 46 cost -132.42075627 Accuracy 0.948\n",
      "epoch 47 cost -132.789727012 Accuracy 0.932\n",
      "epoch 48 cost -132.333770336 Accuracy 0.956\n",
      "epoch 49 cost -132.328536468 Accuracy 0.952\n",
      "epoch 50 cost -132.743525966 Accuracy 0.944\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9713d215bb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0merrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mbatch_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0merrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AdrianHsu/anaconda/envs/python2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # prepare data\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    N = 5000\n",
    "\n",
    "    data = np.float32(mnist.data[:]) / 255.\n",
    "    idx = np.random.choice(data.shape[0], N)\n",
    "    data = data[idx]\n",
    "    target = np.int32(mnist.target[idx]).reshape(N, 1)\n",
    "\n",
    "    train_idx, test_idx = train_test_split(np.array(range(N)), test_size=0.05)\n",
    "    train_data, test_data = data[train_idx], data[test_idx]\n",
    "    train_target, test_target = target[train_idx], target[test_idx]\n",
    "\n",
    "    train_target = np.float32(preprocessing.OneHotEncoder(sparse=False).fit_transform(train_target))\n",
    "\n",
    "    # inputs\n",
    "    x = T.matrix('x')\n",
    "    y = T.matrix('y')\n",
    "    n_input = train_data.shape[1]\n",
    "    M = train_data.shape[0]\n",
    "    sigma_prior = T.exp(-3)\n",
    "    n_samples = 3\n",
    "    learning_rate = 0.001\n",
    "    n_epochs = 100\n",
    "\n",
    "    # weights\n",
    "    # L1\n",
    "    n_hidden_1 = 200\n",
    "    W1_mu = theano.shared(value=init((n_input, n_hidden_1)))\n",
    "    W1_logsigma = theano.shared(value=init((n_input, n_hidden_1)))\n",
    "    b1_mu = theano.shared(value=init((n_hidden_1,)))\n",
    "    b1_logsigma = theano.shared(value=init((n_hidden_1,)))\n",
    "\n",
    "    # L2\n",
    "    n_hidden_2 = 200\n",
    "    W2_mu = theano.shared(value=init((n_hidden_1, n_hidden_2)))\n",
    "    W2_logsigma = theano.shared(value=init((n_hidden_1, n_hidden_2)))\n",
    "    b2_mu = theano.shared(value=init((n_hidden_2,)))\n",
    "    b2_logsigma = theano.shared(value=init((n_hidden_2,)))\n",
    "\n",
    "    # L3\n",
    "    n_output = 10\n",
    "    W3_mu = theano.shared(value=init((n_hidden_2, n_output)))\n",
    "    W3_logsigma = theano.shared(value=init((n_hidden_2, n_output)))\n",
    "    b3_mu = theano.shared(value=init((n_output,)))\n",
    "    b3_logsigma = theano.shared(value=init((n_output,)))\n",
    "\n",
    "    all_params = [\n",
    "        W1_mu, W1_logsigma, b1_mu, b1_logsigma,\n",
    "        W2_mu, W2_logsigma, b2_mu, b2_logsigma,\n",
    "        W3_mu, W3_logsigma, b3_mu, b3_logsigma\n",
    "    ]\n",
    "    all_params = collect_shared_vars(all_params)\n",
    "\n",
    "    # building the objective\n",
    "    # remember, we're evaluating by samples\n",
    "    log_pw, log_qw, log_likelihood = 0., 0., 0.\n",
    "\n",
    "    for _ in xrange(n_samples):\n",
    "\n",
    "        epsilon_w1 = get_random((n_input, n_hidden_1), avg=0., std=sigma_prior)\n",
    "        epsilon_b1 = get_random((n_hidden_1,), avg=0., std=sigma_prior)\n",
    "\n",
    "        W1 = W1_mu + T.log(1. + T.exp(W1_logsigma)) * epsilon_w1\n",
    "        b1 = b1_mu + T.log(1. + T.exp(b1_logsigma)) * epsilon_b1\n",
    "\n",
    "        epsilon_w2 = get_random((n_hidden_1, n_hidden_2), avg=0., std=sigma_prior)\n",
    "        epsilon_b2 = get_random((n_hidden_2,), avg=0., std=sigma_prior)\n",
    "\n",
    "        W2 = W2_mu + T.log(1. + T.exp(W2_logsigma)) * epsilon_w2\n",
    "        b2 = b2_mu + T.log(1. + T.exp(b2_logsigma)) * epsilon_b2\n",
    "\n",
    "        epsilon_w3 = get_random((n_hidden_2, n_output), avg=0., std=sigma_prior)\n",
    "        epsilon_b3 = get_random((n_output,), avg=0., std=sigma_prior)\n",
    "\n",
    "        W3 = W3_mu + T.log(1. + T.exp(W3_logsigma)) * epsilon_w3\n",
    "        b3 = b3_mu + T.log(1. + T.exp(b3_logsigma)) * epsilon_b3\n",
    "\n",
    "        a1 = nonlinearity(T.dot(x, W1) + b1)\n",
    "        a2 = nonlinearity(T.dot(a1, W2) + b2)\n",
    "        h = T.nnet.softmax(nonlinearity(T.dot(a2, W3) + b3))\n",
    "\n",
    "        sample_log_pw, sample_log_qw, sample_log_likelihood = 0., 0., 0.\n",
    "\n",
    "        for W, b, W_mu, W_logsigma, b_mu, b_logsigma in [(W1, b1, W1_mu, W1_logsigma, b1_mu, b1_logsigma),\n",
    "                                                         (W2, b2, W2_mu, W2_logsigma, b2_mu, b2_logsigma),\n",
    "                                                         (W3, b3, W3_mu, W3_logsigma, b3_mu, b3_logsigma)]:\n",
    "\n",
    "            # first weight prior\n",
    "            sample_log_pw += log_gaussian(W, 0., sigma_prior).sum()\n",
    "            sample_log_pw += log_gaussian(b, 0., sigma_prior).sum()\n",
    "\n",
    "            # then approximation\n",
    "            sample_log_qw += log_gaussian_logsigma(W, W_mu, W_logsigma * 2).sum()\n",
    "            sample_log_qw += log_gaussian_logsigma(b, b_mu, b_logsigma * 2).sum()\n",
    "\n",
    "        # then the likelihood\n",
    "        sample_log_likelihood = log_gaussian(y, h, sigma_prior).sum()\n",
    "\n",
    "        log_pw += sample_log_pw\n",
    "        log_qw += sample_log_qw\n",
    "        log_likelihood += sample_log_likelihood\n",
    "\n",
    "    log_qw /= n_samples\n",
    "    log_pw /= n_samples\n",
    "    log_likelihood /= n_samples\n",
    "\n",
    "    batch_size = 100\n",
    "    n_batches = M / float(batch_size)\n",
    "\n",
    "    objective = ((1. / n_batches) * (log_qw - log_pw) - log_likelihood).sum() / float(batch_size)\n",
    "\n",
    "    # updates\n",
    "\n",
    "    updates = adam(objective, all_params, learning_rate=learning_rate)\n",
    "\n",
    "    i = T.iscalar()\n",
    "\n",
    "    train_data = theano.shared(np.asarray(train_data, dtype=theano.config.floatX))\n",
    "    train_target = theano.shared(np.asarray(train_target, dtype=theano.config.floatX))\n",
    "\n",
    "    train_function = theano.function(\n",
    "        inputs=[i],\n",
    "        outputs=objective,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_data[i * batch_size: (i + 1) * batch_size],\n",
    "            y: train_target[i * batch_size: (i + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    a1_mu = nonlinearity(T.dot(x, W1_mu) + b1_mu)\n",
    "    a2_mu = nonlinearity(T.dot(a1_mu, W2_mu) + b2_mu)\n",
    "    h_mu = T.nnet.softmax(nonlinearity(T.dot(a2_mu, W3_mu) + b3_mu))\n",
    "\n",
    "    output_function = theano.function([x], T.argmax(h_mu, axis=1))\n",
    "\n",
    "    n_train_batches = int(train_data.get_value().shape[0] / float(batch_size))\n",
    "\n",
    "    # and finally, training loop\n",
    "    for e in xrange(n_epochs):\n",
    "        errs = []\n",
    "        for b in xrange(n_train_batches):\n",
    "            batch_err = train_function(b)\n",
    "            errs.append(batch_err)\n",
    "        out = output_function(test_data)\n",
    "        acc = np.count_nonzero(output_function(test_data) == np.int32(test_target.ravel())) / float(test_data.shape[0])\n",
    "        print 'epoch', e, 'cost', np.mean(errs), 'Accuracy', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
