{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\" Auto Encoder Example.\n",
    "Using an auto encoder on MNIST handwritten digits.\n",
    "References:\n",
    "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based\n",
    "    learning applied to document recognition.\" Proceedings of the IEEE,\n",
    "    86(11):2278-2324, November 1998.\n",
    "Links:\n",
    "    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n",
    "\"\"\"\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import MNIST data\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "df = pd.read_csv(\"../dat/diabetic.txt\", header=None);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.shape #(1151, 20)\n",
    "#type(data) #pandas.core.frame.DataFrame\n",
    "train = df.head(1000)\n",
    "train_x = train.T.head(18)\n",
    "train_y = train.T.tail(1)\n",
    "test = df.tail(151)\n",
    "test_x = test.T.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 968.337768555\n",
      "Epoch: 0002 cost= 960.324096680\n",
      "Epoch: 0003 cost= 958.272216797\n",
      "Epoch: 0004 cost= 957.918212891\n",
      "Epoch: 0005 cost= 957.895996094\n",
      "Epoch: 0006 cost= 957.898437500\n",
      "Epoch: 0007 cost= 957.880249023\n",
      "Epoch: 0008 cost= 957.876220703\n",
      "Epoch: 0009 cost= 957.874572754\n",
      "Epoch: 0010 cost= 957.874023438\n",
      "Epoch: 0011 cost= 957.873779297\n",
      "Epoch: 0012 cost= 957.873535156\n",
      "Epoch: 0013 cost= 957.873107910\n",
      "Epoch: 0014 cost= 957.872680664\n",
      "Epoch: 0015 cost= 957.872680664\n",
      "Epoch: 0016 cost= 957.872436523\n",
      "Epoch: 0017 cost= 957.872436523\n",
      "Epoch: 0018 cost= 957.872192383\n",
      "Epoch: 0019 cost= 957.872192383\n",
      "Epoch: 0020 cost= 957.872192383\n",
      "Epoch: 0021 cost= 957.871765137\n",
      "Epoch: 0022 cost= 957.871643066\n",
      "Epoch: 0023 cost= 957.871582031\n",
      "Epoch: 0024 cost= 957.871215820\n",
      "Epoch: 0025 cost= 957.871215820\n",
      "Epoch: 0026 cost= 957.871215820\n",
      "Epoch: 0027 cost= 957.871215820\n",
      "Epoch: 0028 cost= 957.870971680\n",
      "Epoch: 0029 cost= 957.870910645\n",
      "Epoch: 0030 cost= 957.870910645\n",
      "Epoch: 0031 cost= 957.870666504\n",
      "Epoch: 0032 cost= 957.870544434\n",
      "Epoch: 0033 cost= 957.870361328\n",
      "Epoch: 0034 cost= 957.870361328\n",
      "Epoch: 0035 cost= 957.870361328\n",
      "Epoch: 0036 cost= 957.870239258\n",
      "Epoch: 0037 cost= 957.870239258\n",
      "Epoch: 0038 cost= 957.870239258\n",
      "Epoch: 0039 cost= 957.870239258\n",
      "Epoch: 0040 cost= 957.870239258\n",
      "Epoch: 0041 cost= 957.870239258\n",
      "Epoch: 0042 cost= 957.870239258\n",
      "Epoch: 0043 cost= 957.870239258\n",
      "Epoch: 0044 cost= 957.870239258\n",
      "Epoch: 0045 cost= 957.870239258\n",
      "Epoch: 0046 cost= 957.870239258\n",
      "Epoch: 0047 cost= 957.869995117\n",
      "Epoch: 0048 cost= 957.869995117\n",
      "Epoch: 0049 cost= 957.869995117\n",
      "Epoch: 0050 cost= 957.869995117\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (151, 20) for Tensor u'Placeholder_15:0', which has shape '(?, 1000)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0d88dad39a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Applying encode and decode over test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     encode_decode = sess.run(\n\u001b[0;32m---> 88\u001b[0;31m         y_pred, feed_dict={X: test_x.T}) #{X: mnist.test.images[:examples_to_show]})\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;31m#     # Compare original images with their reconstructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m#     f, a = plt.subplots(2, 10, figsize=(10, 2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adrianhsu/root/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adrianhsu/root/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (151, 20) for Tensor u'Placeholder_15:0', which has shape '(?, 1000)'"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 50\n",
    "# batch_size = 256\n",
    "batch_size = 19\n",
    "display_step = 1\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 19 # 1st layer num features\n",
    "n_hidden_2 = 128 # 2nd layer num features\n",
    "n_input = 1000 # MNIST data input (img shape: 28*28)\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n",
    "}\n",
    "\n",
    "\n",
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                   biases['decoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    total_batch = int(n_input / batch_size) #(mnist.train.num_examples/batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = train_x, train_y# mnist.train.next_batch(batch_size) # 256x1, 256x1\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "                  \"cost=\", \"{:.9f}\".format(c))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Applying encode and decode over test set\n",
    "    encode_decode = sess.run(\n",
    "        y_pred, feed_dict={X: test_x.T}) #{X: mnist.test.images[:examples_to_show]})\n",
    "#     # Compare original images with their reconstructions\n",
    "#     f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
    "#     for i in range(examples_to_show):\n",
    "#         a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "#         a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "#     f.show()\n",
    "#     plt.draw()\n",
    "#     plt.waitforbuttonpress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>...</th>\n",
       "      <th>1141</th>\n",
       "      <th>1142</th>\n",
       "      <th>1143</th>\n",
       "      <th>1144</th>\n",
       "      <th>1145</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.805279</td>\n",
       "      <td>61.559348</td>\n",
       "      <td>169.099820</td>\n",
       "      <td>87.943106</td>\n",
       "      <td>276.491407</td>\n",
       "      <td>59.655889</td>\n",
       "      <td>38.812879</td>\n",
       "      <td>16.740482</td>\n",
       "      <td>20.384375</td>\n",
       "      <td>69.952496</td>\n",
       "      <td>...</td>\n",
       "      <td>8.632010</td>\n",
       "      <td>25.283836</td>\n",
       "      <td>243.066702</td>\n",
       "      <td>2.579859</td>\n",
       "      <td>158.177307</td>\n",
       "      <td>6.071765</td>\n",
       "      <td>63.197145</td>\n",
       "      <td>30.461898</td>\n",
       "      <td>40.525739</td>\n",
       "      <td>69.423565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.866246</td>\n",
       "      <td>28.959444</td>\n",
       "      <td>78.742242</td>\n",
       "      <td>28.050493</td>\n",
       "      <td>130.357061</td>\n",
       "      <td>22.852706</td>\n",
       "      <td>27.759006</td>\n",
       "      <td>8.434313</td>\n",
       "      <td>10.683792</td>\n",
       "      <td>40.476639</td>\n",
       "      <td>...</td>\n",
       "      <td>3.852405</td>\n",
       "      <td>8.337976</td>\n",
       "      <td>26.650463</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>84.865487</td>\n",
       "      <td>0.937472</td>\n",
       "      <td>27.377668</td>\n",
       "      <td>13.966980</td>\n",
       "      <td>12.604947</td>\n",
       "      <td>7.031843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.442991</td>\n",
       "      <td>12.778104</td>\n",
       "      <td>36.806527</td>\n",
       "      <td>8.759721</td>\n",
       "      <td>43.529055</td>\n",
       "      <td>9.441730</td>\n",
       "      <td>23.005114</td>\n",
       "      <td>0.453906</td>\n",
       "      <td>8.147488</td>\n",
       "      <td>4.905881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383992</td>\n",
       "      <td>0.720774</td>\n",
       "      <td>13.732893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.253664</td>\n",
       "      <td>0.031145</td>\n",
       "      <td>8.067688</td>\n",
       "      <td>1.763305</td>\n",
       "      <td>4.740919</td>\n",
       "      <td>1.750548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.395844</td>\n",
       "      <td>2.045287</td>\n",
       "      <td>4.141645</td>\n",
       "      <td>1.136672</td>\n",
       "      <td>2.821299</td>\n",
       "      <td>0.739028</td>\n",
       "      <td>15.172345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.674239</td>\n",
       "      <td>0.357330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290335</td>\n",
       "      <td>0.036805</td>\n",
       "      <td>0.099581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.283321</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.979548</td>\n",
       "      <td>0.137858</td>\n",
       "      <td>1.077570</td>\n",
       "      <td>0.046597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.124092</td>\n",
       "      <td>0.038016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040814</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.067801</td>\n",
       "      <td>12.584615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.857293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>0.563518</td>\n",
       "      <td>0.021180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.566725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>1.793709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.203690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.008472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.217331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.713220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239568</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.142461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.269718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.555322</td>\n",
       "      <td>0.527993</td>\n",
       "      <td>0.561594</td>\n",
       "      <td>0.491819</td>\n",
       "      <td>0.474780</td>\n",
       "      <td>0.479596</td>\n",
       "      <td>0.566874</td>\n",
       "      <td>0.478857</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>0.483614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551013</td>\n",
       "      <td>0.471802</td>\n",
       "      <td>0.553246</td>\n",
       "      <td>0.537551</td>\n",
       "      <td>0.533177</td>\n",
       "      <td>0.537470</td>\n",
       "      <td>0.516733</td>\n",
       "      <td>0.560632</td>\n",
       "      <td>0.485972</td>\n",
       "      <td>0.556192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.115425</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>0.103021</td>\n",
       "      <td>0.118361</td>\n",
       "      <td>0.067198</td>\n",
       "      <td>0.123978</td>\n",
       "      <td>0.080835</td>\n",
       "      <td>0.111161</td>\n",
       "      <td>0.104897</td>\n",
       "      <td>0.137315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087413</td>\n",
       "      <td>0.141088</td>\n",
       "      <td>0.084022</td>\n",
       "      <td>0.124181</td>\n",
       "      <td>0.104430</td>\n",
       "      <td>0.116795</td>\n",
       "      <td>0.124190</td>\n",
       "      <td>0.129843</td>\n",
       "      <td>0.106690</td>\n",
       "      <td>0.088957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1000       1001        1002       1003        1004       1005  \\\n",
       "0    1.000000   1.000000    1.000000   1.000000    1.000000   1.000000   \n",
       "1    1.000000   1.000000    1.000000   0.000000    0.000000   0.000000   \n",
       "2   35.000000  79.000000    5.000000   8.000000    6.000000  18.000000   \n",
       "3   31.000000  76.000000    4.000000   8.000000    6.000000  17.000000   \n",
       "4   28.000000  74.000000    4.000000   8.000000    6.000000  17.000000   \n",
       "5   25.000000  72.000000    4.000000   8.000000    6.000000  17.000000   \n",
       "6   20.000000  69.000000    4.000000   5.000000    5.000000  14.000000   \n",
       "7   16.000000  50.000000    3.000000   4.000000    4.000000  14.000000   \n",
       "8   52.805279  61.559348  169.099820  87.943106  276.491407  59.655889   \n",
       "9   27.866246  28.959444   78.742242  28.050493  130.357061  22.852706   \n",
       "10   6.442991  12.778104   36.806527   8.759721   43.529055   9.441730   \n",
       "11   2.395844   2.045287    4.141645   1.136672    2.821299   0.739028   \n",
       "12   1.124092   0.038016    0.000000   0.040814    0.022399   0.067801   \n",
       "13   0.566725   0.000000    0.000000   0.000000    0.001018   0.008717   \n",
       "14   0.217331   0.000000    0.000000   0.000000    0.001018   0.000000   \n",
       "15   0.142461   0.000000    0.000000   0.000000    0.001018   0.000000   \n",
       "16   0.555322   0.527993    0.561594   0.491819    0.474780   0.479596   \n",
       "17   0.115425   0.101884    0.103021   0.118361    0.067198   0.123978   \n",
       "18   0.000000   0.000000    0.000000   1.000000    1.000000   1.000000   \n",
       "19   1.000000   1.000000    0.000000   0.000000    1.000000   1.000000   \n",
       "\n",
       "         1006       1007       1008       1009    ...           1141  \\\n",
       "0    1.000000   1.000000   1.000000   1.000000    ...       1.000000   \n",
       "1    0.000000   1.000000   1.000000   1.000000    ...       1.000000   \n",
       "2   29.000000  35.000000  92.000000  43.000000    ...      53.000000   \n",
       "3   28.000000  35.000000  84.000000  43.000000    ...      53.000000   \n",
       "4   26.000000  34.000000  78.000000  43.000000    ...      52.000000   \n",
       "5   22.000000  32.000000  71.000000  39.000000    ...      51.000000   \n",
       "6   17.000000  30.000000  60.000000  36.000000    ...      51.000000   \n",
       "7   11.000000  22.000000  43.000000  28.000000    ...      41.000000   \n",
       "8   38.812879  16.740482  20.384375  69.952496    ...       8.632010   \n",
       "9   27.759006   8.434313  10.683792  40.476639    ...       3.852405   \n",
       "10  23.005114   0.453906   8.147488   4.905881    ...       0.383992   \n",
       "11  15.172345   0.000000   6.674239   0.357330    ...       0.290335   \n",
       "12  12.584615   0.000000   5.694161   0.000000    ...       0.165460   \n",
       "13   1.793709   0.000000   4.203690   0.000000    ...       0.109266   \n",
       "14   0.000000   0.000000   2.713220   0.000000    ...       0.085852   \n",
       "15   0.000000   0.000000   1.269718   0.000000    ...       0.071803   \n",
       "16   0.566874   0.478857   0.521502   0.483614    ...       0.551013   \n",
       "17   0.080835   0.111161   0.104897   0.137315    ...       0.087413   \n",
       "18   0.000000   1.000000   0.000000   0.000000    ...       1.000000   \n",
       "19   1.000000   0.000000   1.000000   0.000000    ...       1.000000   \n",
       "\n",
       "         1142        1143       1144        1145       1146       1147  \\\n",
       "0    1.000000    1.000000   1.000000    1.000000   1.000000   1.000000   \n",
       "1    1.000000    1.000000   1.000000    1.000000   1.000000   1.000000   \n",
       "2   53.000000   12.000000  35.000000   16.000000  34.000000  49.000000   \n",
       "3   53.000000   12.000000  34.000000   16.000000  34.000000  49.000000   \n",
       "4   51.000000   10.000000  33.000000   15.000000  34.000000  49.000000   \n",
       "5   47.000000    9.000000  33.000000   14.000000  33.000000  49.000000   \n",
       "6   44.000000    7.000000  33.000000   12.000000  31.000000  45.000000   \n",
       "7   32.000000    6.000000  26.000000    8.000000  24.000000  37.000000   \n",
       "8   25.283836  243.066702   2.579859  158.177307   6.071765  63.197145   \n",
       "9    8.337976   26.650463   0.001552   84.865487   0.937472  27.377668   \n",
       "10   0.720774   13.732893   0.000000   51.253664   0.031145   8.067688   \n",
       "11   0.036805    0.099581   0.000000   11.283321   0.003115   0.979548   \n",
       "12   0.000000    0.002075   0.000000    1.857293   0.000000   0.001552   \n",
       "13   0.000000    0.001037   0.000000    0.019520   0.000000   0.000000   \n",
       "14   0.000000    0.000000   0.000000    0.006832   0.000000   0.000000   \n",
       "15   0.000000    0.000000   0.000000    0.001952   0.000000   0.000000   \n",
       "16   0.471802    0.553246   0.537551    0.533177   0.537470   0.516733   \n",
       "17   0.141088    0.084022   0.124181    0.104430   0.116795   0.124190   \n",
       "18   0.000000    1.000000   0.000000    1.000000   0.000000   0.000000   \n",
       "19   0.000000    1.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "\n",
       "         1148       1149       1150  \n",
       "0    1.000000   1.000000   1.000000  \n",
       "1    0.000000   1.000000   1.000000  \n",
       "2   49.000000  39.000000   7.000000  \n",
       "3   48.000000  36.000000   7.000000  \n",
       "4   48.000000  29.000000   7.000000  \n",
       "5   45.000000  23.000000   7.000000  \n",
       "6   43.000000  13.000000   7.000000  \n",
       "7   33.000000   7.000000   5.000000  \n",
       "8   30.461898  40.525739  69.423565  \n",
       "9   13.966980  12.604947   7.031843  \n",
       "10   1.763305   4.740919   1.750548  \n",
       "11   0.137858   1.077570   0.046597  \n",
       "12   0.011221   0.563518   0.021180  \n",
       "13   0.000000   0.326860   0.008472  \n",
       "14   0.000000   0.239568   0.000000  \n",
       "15   0.000000   0.174584   0.000000  \n",
       "16   0.560632   0.485972   0.556192  \n",
       "17   0.129843   0.106690   0.088957  \n",
       "18   0.000000   1.000000   0.000000  \n",
       "19   0.000000   1.000000   0.000000  \n",
       "\n",
       "[20 rows x 151 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
