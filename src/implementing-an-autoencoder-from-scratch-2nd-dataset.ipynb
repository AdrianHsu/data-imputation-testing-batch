{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler,scale\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_RATE = 1\n",
    "TESTING_RATE = 1 - TRAINING_RATE\n",
    "MISSING_RATE = 0.5\n",
    "QUERY_RATE = 0.2\n",
    "# np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a dataset and plot it\n",
    "np.random.seed(0)\n",
    "#X : array of shape [n_samples, 2]\n",
    "# e.g. X[0,:]  is [0.74, 0.46]\n",
    "# X, y = sklearn.datasets.load_files(\"../dat/wine_quality\") # X is 2 x 1 vector for 200 n_samples , y is 0 or 1\n",
    "data = pd.read_csv(\"../dat/wine_quality/winequality-white.csv\",sep=';')\n",
    "# plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(d):\n",
    "    #Add normalization code here if necessary\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "#     d.ix[:,0:-1] = scale(d.ix[:,0:-1])\n",
    "    d.ix[:,0:-1] = min_max_scaler.fit_transform(d.ix[:,0:-1])\n",
    "    #d['quality'] = d['quality'].apply(lambda x:1.0 if x==6 else 0.0)\n",
    "    d['quality'] = d['quality'].apply(lambda x: int(x) -3)\n",
    "    d = d.iloc[np.random.permutation(len(d))]\n",
    "    t = int(len(d) * TRAINING_RATE)\n",
    "    tn_data = d.iloc[0:t,:]\n",
    "    tt_data = d.iloc[t:,:]\n",
    "    \n",
    "    tn_X = tn_data.ix[:,0:-1]\n",
    "    tn_Y = tn_data.ix[:,-1]\n",
    "    tt_X = tt_data.ix[:,0:-1]\n",
    "    tt_Y = tt_data.ix[:,-1]\n",
    "    \n",
    "    \n",
    "    return tn_X,tn_Y, tt_X, tt_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.336538</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.121662</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.357309</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.435484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>0.178042</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>0.350348</td>\n",
       "      <td>0.159823</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>0.087108</td>\n",
       "      <td>0.218097</td>\n",
       "      <td>0.086563</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.078221</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.181185</td>\n",
       "      <td>0.338747</td>\n",
       "      <td>0.051089</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.790323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.177147</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>0.139373</td>\n",
       "      <td>0.357309</td>\n",
       "      <td>0.165606</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.338710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.271084</td>\n",
       "      <td>0.122699</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.412993</td>\n",
       "      <td>0.236939</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.432692</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.059049</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.280742</td>\n",
       "      <td>0.101986</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.056748</td>\n",
       "      <td>0.050445</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.180974</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>0.354545</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.103914</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.168712</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>0.209059</td>\n",
       "      <td>0.466357</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.241935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.153374</td>\n",
       "      <td>0.089021</td>\n",
       "      <td>0.104530</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.175246</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.338710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.187117</td>\n",
       "      <td>0.157270</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.375870</td>\n",
       "      <td>0.211490</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.044479</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.125290</td>\n",
       "      <td>0.127048</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.111963</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.181185</td>\n",
       "      <td>0.461717</td>\n",
       "      <td>0.165992</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.177419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.355769</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.232019</td>\n",
       "      <td>0.064199</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>0.629032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0        0.336538          0.235294     0.210843        0.012270   0.121662   \n",
       "1        0.307692          0.225490     0.156627        0.104294   0.178042   \n",
       "2        0.365385          0.058824     0.445783        0.015337   0.091988   \n",
       "3        0.115385          0.205882     0.325301        0.078221   0.077151   \n",
       "4        0.211538          0.196078     0.132530        0.177147   0.115727   \n",
       "5        0.576923          0.833333     0.271084        0.122699   0.127596   \n",
       "6        0.432692          0.117647     0.445783        0.059049   0.103858   \n",
       "7        0.375000          0.225490     0.216867        0.056748   0.050445   \n",
       "8        0.326923          0.098039     0.186747        0.007669   0.106825   \n",
       "9        0.230769          0.166667     0.283133        0.168712   0.115727   \n",
       "10       0.259615          0.205882     0.150602        0.153374   0.089021   \n",
       "11       0.288462          0.098039     0.180723        0.187117   0.157270   \n",
       "12       0.307692          0.254902     0.060241        0.044479   0.103858   \n",
       "13       0.230769          0.166667     0.228916        0.111963   0.106825   \n",
       "14       0.355769          0.176471     0.186747        0.015337   0.068249   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0              0.020906              0.357309  0.102757  0.472727   0.232558   \n",
       "1              0.090592              0.350348  0.159823  0.372727   0.279070   \n",
       "2              0.087108              0.218097  0.086563  0.318182   0.209302   \n",
       "3              0.181185              0.338747  0.051089  0.500000   0.139535   \n",
       "4              0.139373              0.357309  0.165606  0.436364   0.279070   \n",
       "5              0.111498              0.412993  0.236939  0.363636   0.430233   \n",
       "6              0.108014              0.280742  0.101986  0.481818   0.232558   \n",
       "7              0.045296              0.180974  0.085020  0.354545   0.302326   \n",
       "8              0.062718              0.148492  0.103914  0.545455   0.209302   \n",
       "9              0.209059              0.466357  0.186813  0.427273   0.325581   \n",
       "10             0.104530              0.257541  0.175246  0.536364   0.139535   \n",
       "11             0.059233              0.375870  0.211490  0.254545   0.348837   \n",
       "12             0.052265              0.125290  0.127048  0.263636   0.197674   \n",
       "13             0.181185              0.461717  0.165992  0.409091   0.279070   \n",
       "14             0.118467              0.232019  0.064199  0.227273   0.244186   \n",
       "\n",
       "     alcohol  \n",
       "0   0.435484  \n",
       "1   0.290323  \n",
       "2   0.451613  \n",
       "3   0.790323  \n",
       "4   0.338710  \n",
       "5   0.354839  \n",
       "6   0.677419  \n",
       "7   0.645161  \n",
       "8   0.451613  \n",
       "9   0.241935  \n",
       "10  0.338710  \n",
       "11  0.161290  \n",
       "12  0.193548  \n",
       "13  0.177419  \n",
       "14  0.629032  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tn_X,tn_Y,tt_X,tt_Y = preprocessing(data)\n",
    "X, y,tt_X,tt_Y = preprocessing(data)\n",
    "X = X.reset_index(drop=True)\n",
    "X.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-599c03dcedcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# X.ix[0,0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# change type \"DataFrame\" (of Pandas) to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "# X.ix[0,0]\n",
    "X = X.as_matrix() # change type \"DataFrame\" (of Pandas) to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33653846,  0.23529412,  0.21084337, ...,  0.47272727,\n",
       "         0.23255814,  0.43548387],\n",
       "       [ 0.30769231,  0.2254902 ,  0.15662651, ...,  0.37272727,\n",
       "         0.27906977,  0.29032258],\n",
       "       [ 0.36538462,  0.05882353,  0.44578313, ...,  0.31818182,\n",
       "         0.20930233,  0.4516129 ],\n",
       "       ..., \n",
       "       [ 0.39423077,  0.24509804,  0.1686747 , ...,  0.39090909,\n",
       "         0.18604651,  0.12903226],\n",
       "       [ 0.49038462,  0.17647059,  0.19879518, ...,  0.37272727,\n",
       "         0.27906977,  0.4516129 ],\n",
       "       [ 0.39423077,  0.42156863,  0.20481928, ...,  0.33636364,\n",
       "         0.3372093 ,  0.32258065]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to predict an output (0 or 1)\n",
    "def predict(model, x):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Forward propagation\n",
    "    z1 = x.dot(W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = a1.dot(W2) + b2 # 200 x 2 -> (200 x 3) * (3 x 2)\n",
    "#     a2 = sigmoid(z2) # 200 x 2\n",
    "    a2 = z2\n",
    "    return np.argmax(a2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Forward propagation\n",
    "    z1 = X.dot(W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    corect_probs = np.square(a2 - X) * (1/2)\n",
    "    data_loss = np.sum(corect_probs)\n",
    "    return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot a decision boundary.\n",
    "# If you don't fully understand this function don't worry, it just generates the contour plot below.\n",
    "def plot_decision_boundary(pred_func):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 11)\n"
     ]
    }
   ],
   "source": [
    "num_examples = len(X)\n",
    "nn_input_dim = 11\n",
    "nn_output_dim = 11\n",
    "epsilon = 0.01 #GD update\n",
    "reg_lambda = 0.01\n",
    "loss = []\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):                                        \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(nn_hdim, num_passes=5000, print_loss=False):\n",
    "    np.random.seed() # X is 200 x 2\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim) # 2 x 3\n",
    "    b1 = np.zeros((1, nn_hdim)) # 1 x 3\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim) # 3 x 2\n",
    "    b2 = np.zeros((1, nn_output_dim)) # 1 x 2\n",
    "    \n",
    "    model = {}\n",
    "    \n",
    "    # Gradient Descent in batch\n",
    "    for i in range(0, num_passes):\n",
    "        \n",
    "        # Forward propagation\n",
    "        z1 = X.dot(W1) + b1 #200 x 3 -> (200 x 2) dot (2 x 3)\n",
    "        a1 = sigmoid(z1) # 200 x 3\n",
    "        z2 = a1.dot(W2) + b2 # 200 x 2 -> (200 x 3) * (3 x 2)\n",
    "        a2 = sigmoid(z2) # 200 x 2\n",
    "        # Backpropagation\n",
    "        delta2 = (a2 * (1 - a2)) * (a2 - X) # 200 x 2 -> (200 x 2) * (200 x 2) \n",
    "        dW2 = (a1.T).dot(delta2) # 3 x 2 -> (3 x 200) dot (200 x 2)\n",
    "        db2 = np.sum(delta2, axis=0, keepdims=True) # ? x ?\n",
    "        delta1 = (a1 * (1 - a1)) * (delta2.dot(W2.T)) # 200 x 3 -> (200 x 3) * ((200 x 2) dot (2 x 3))\n",
    "        dW1 = (X.T).dot(delta1) # 2 x 3 -> (2 x 200) dot (200 x 3)\n",
    "        db1 = np.sum(delta1, axis=0) # ? x ?\n",
    "        \n",
    "        \n",
    "        # Gradient descent parameter update\n",
    "        W1 += -epsilon * dW1\n",
    "        b1 += -epsilon * db1\n",
    "        W2 += -epsilon * dW2\n",
    "        b2 += -epsilon * db2\n",
    "        # Assign new parameters to the model\n",
    "        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "        if print_loss and i % 100 == 0:\n",
    "            tmp = calculate_loss(model)\n",
    "            print( \"Loss after iteration %i: %f\" %(i, tmp) )\n",
    "            loss.append(tmp)\n",
    "    return model, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 1488.608424\n",
      "Loss after iteration 100: 561.107679\n",
      "Loss after iteration 200: 629.756814\n",
      "Loss after iteration 300: 505.577291\n",
      "Loss after iteration 400: 370.514314\n",
      "Loss after iteration 500: 412.052116\n",
      "Loss after iteration 600: 275.415778\n",
      "Loss after iteration 700: 284.455015\n",
      "Loss after iteration 800: 280.892598\n",
      "Loss after iteration 900: 256.152403\n",
      "Loss after iteration 1000: 443.042767\n",
      "Loss after iteration 1100: 374.977139\n",
      "Loss after iteration 1200: 457.485685\n",
      "Loss after iteration 1300: 293.640330\n",
      "Loss after iteration 1400: 335.788194\n",
      "Loss after iteration 1500: 357.777487\n",
      "Loss after iteration 1600: 350.087850\n",
      "Loss after iteration 1700: 344.050280\n",
      "Loss after iteration 1800: 334.493185\n",
      "Loss after iteration 1900: 405.750599\n",
      "Loss after iteration 2000: 321.446119\n",
      "Loss after iteration 2100: 377.115800\n",
      "Loss after iteration 2200: 364.892767\n",
      "Loss after iteration 2300: 363.907820\n",
      "Loss after iteration 2400: 355.705305\n",
      "Loss after iteration 2500: 339.266279\n",
      "Loss after iteration 2600: 386.140241\n",
      "Loss after iteration 2700: 320.271372\n",
      "Loss after iteration 2800: 282.994653\n",
      "Loss after iteration 2900: 339.604942\n",
      "Loss after iteration 3000: 335.586799\n",
      "Loss after iteration 3100: 334.362071\n",
      "Loss after iteration 3200: 261.607828\n",
      "Loss after iteration 3300: 350.146936\n",
      "Loss after iteration 3400: 339.665649\n",
      "Loss after iteration 3500: 303.520414\n",
      "Loss after iteration 3600: 334.660942\n",
      "Loss after iteration 3700: 310.567560\n",
      "Loss after iteration 3800: 330.544846\n",
      "Loss after iteration 3900: 296.693596\n",
      "Loss after iteration 4000: 332.938759\n",
      "Loss after iteration 4100: 353.762022\n",
      "Loss after iteration 4200: 350.849201\n",
      "Loss after iteration 4300: 318.159250\n",
      "Loss after iteration 4400: 519.991410\n",
      "Loss after iteration 4500: 182.908138\n",
      "Loss after iteration 4600: 298.190006\n",
      "Loss after iteration 4700: 319.635416\n",
      "Loss after iteration 4800: 249.829867\n",
      "Loss after iteration 4900: 305.500144\n"
     ]
    }
   ],
   "source": [
    "# Build a model with a 3-dimensional hidden layer\n",
    "model, a2 = build_model(3, print_loss=True)\n",
    " \n",
    "# Plot the decision boundary -> no use for autoencoder\n",
    "# plot_decision_boundary(lambda x: predict(model, x))\n",
    "# plt.title(\"Decision Boundary for hidden layer size 3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10cbd1da0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQS7P8DegabavqhcWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c2bd470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33653846,  0.23529412,  0.21084337, ...,  0.47272727,\n",
       "         0.23255814,  0.43548387],\n",
       "       [ 0.30769231,  0.2254902 ,  0.15662651, ...,  0.37272727,\n",
       "         0.27906977,  0.29032258],\n",
       "       [ 0.36538462,  0.05882353,  0.44578313, ...,  0.31818182,\n",
       "         0.20930233,  0.4516129 ],\n",
       "       ..., \n",
       "       [ 0.39423077,  0.24509804,  0.1686747 , ...,  0.39090909,\n",
       "         0.18604651,  0.12903226],\n",
       "       [ 0.49038462,  0.17647059,  0.19879518, ...,  0.37272727,\n",
       "         0.27906977,  0.4516129 ],\n",
       "       [ 0.39423077,  0.42156863,  0.20481928, ...,  0.33636364,\n",
       "         0.3372093 ,  0.32258065]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99999998e-01,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "          5.06565739e-10,   0.00000000e+00,   1.68433561e-59],\n",
       "       [  9.99999997e-01,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "          9.52184281e-10,   0.00000000e+00,   9.37284048e-58],\n",
       "       [  9.99999997e-01,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "          1.00651293e-09,   0.00000000e+00,   1.45818934e-57],\n",
       "       ..., \n",
       "       [  9.99999997e-01,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "          7.02424119e-10,   0.00000000e+00,   1.93082737e-58],\n",
       "       [  9.99999999e-01,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "          2.79511977e-10,   0.00000000e+00,   5.12819811e-61],\n",
       "       [  9.99999998e-01,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "          6.37936211e-10,   0.00000000e+00,   9.28200201e-59]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22009061,  0.29238754,  0.31138409, ...,  0.11173554,\n",
       "         0.02704164,  0.0948231 ],\n",
       "       [ 0.23964497,  0.29993272,  0.35563943, ...,  0.06946281,\n",
       "         0.03893997,  0.0421436 ],\n",
       "       [ 0.20136834,  0.44290657,  0.15357817, ...,  0.05061983,\n",
       "         0.02190373,  0.10197711],\n",
       "       ..., \n",
       "       [ 0.18347818,  0.28493849,  0.34555088, ...,  0.07640496,\n",
       "         0.01730665,  0.00832466],\n",
       "       [ 0.12985392,  0.33910035,  0.32096458, ...,  0.06946281,\n",
       "         0.03893997,  0.10197711],\n",
       "       [ 0.18347818,  0.16729143,  0.31615619, ...,  0.05657025,\n",
       "         0.05685506,  0.05202914]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(a2 - X) * (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(np.array([1,2])-np.array([3,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
