{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler,scale\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_RATE = 1\n",
    "TESTING_RATE = 1 - TRAINING_RATE\n",
    "MISSING_RATE = 0.5\n",
    "QUERY_RATE = 0.2\n",
    "# np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a dataset and plot it\n",
    "np.random.seed(0)\n",
    "#X : array of shape [n_samples, 2]\n",
    "# e.g. X[0,:]  is [0.74, 0.46]\n",
    "# X, y = sklearn.datasets.load_files(\"../dat/wine_quality\") # X is 2 x 1 vector for 200 n_samples , y is 0 or 1\n",
    "data = pd.read_csv(\"../dat/wine_quality/winequality-white.csv\",sep=';')\n",
    "# plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(d):\n",
    "    #Add normalization code here if necessary\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    d.ix[:,0:-1] = scale(d.ix[:,0:-1])\n",
    "#     d.ix[:,0:-1] = min_max_scaler.fit_transform(d.ix[:,0:-1])\n",
    "    #d['quality'] = d['quality'].apply(lambda x:1.0 if x==6 else 0.0)\n",
    "    d['quality'] = d['quality'].apply(lambda x: int(x) -3)\n",
    "    d = d.iloc[np.random.permutation(len(d))]\n",
    "    t = int(len(d) * TRAINING_RATE)\n",
    "    tn_data = d.iloc[0:t,:]\n",
    "    tt_data = d.iloc[t:,:]\n",
    "    \n",
    "    tn_X = tn_data.ix[:,0:-1]\n",
    "    tn_Y = tn_data.ix[:,-1]\n",
    "    tt_X = tt_data.ix[:,0:-1]\n",
    "    tt_Y = tt_data.ix[:,-1]\n",
    "    \n",
    "    \n",
    "    return tn_X,tn_Y, tt_X, tt_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.064931</td>\n",
       "      <td>-0.577879</td>\n",
       "      <td>0.295920</td>\n",
       "      <td>1.736866</td>\n",
       "      <td>0.239298</td>\n",
       "      <td>1.922443</td>\n",
       "      <td>0.932828</td>\n",
       "      <td>1.779784</td>\n",
       "      <td>1.402345</td>\n",
       "      <td>3.156077</td>\n",
       "      <td>-0.986812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.301959</td>\n",
       "      <td>-0.875545</td>\n",
       "      <td>0.791757</td>\n",
       "      <td>0.888997</td>\n",
       "      <td>-0.035355</td>\n",
       "      <td>1.040370</td>\n",
       "      <td>0.368039</td>\n",
       "      <td>1.167867</td>\n",
       "      <td>2.197125</td>\n",
       "      <td>2.455025</td>\n",
       "      <td>-0.092863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.379435</td>\n",
       "      <td>-0.365197</td>\n",
       "      <td>-0.668715</td>\n",
       "      <td>-0.447335</td>\n",
       "      <td>-1.076604</td>\n",
       "      <td>-0.502678</td>\n",
       "      <td>0.027628</td>\n",
       "      <td>1.137419</td>\n",
       "      <td>1.666341</td>\n",
       "      <td>-0.336667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.250071</td>\n",
       "      <td>-1.073988</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>-0.905330</td>\n",
       "      <td>-0.035355</td>\n",
       "      <td>3.568979</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>-1.229644</td>\n",
       "      <td>1.269882</td>\n",
       "      <td>3.594234</td>\n",
       "      <td>1.044891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.183445</td>\n",
       "      <td>-0.577879</td>\n",
       "      <td>-0.034638</td>\n",
       "      <td>-1.023637</td>\n",
       "      <td>-0.447335</td>\n",
       "      <td>0.040688</td>\n",
       "      <td>-1.232197</td>\n",
       "      <td>-1.152737</td>\n",
       "      <td>-0.584605</td>\n",
       "      <td>2.367393</td>\n",
       "      <td>0.719818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.883181</td>\n",
       "      <td>-1.073988</td>\n",
       "      <td>1.039676</td>\n",
       "      <td>-1.082790</td>\n",
       "      <td>-0.447335</td>\n",
       "      <td>1.628419</td>\n",
       "      <td>0.203309</td>\n",
       "      <td>-0.925358</td>\n",
       "      <td>-1.114458</td>\n",
       "      <td>-0.699710</td>\n",
       "      <td>0.150942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.764667</td>\n",
       "      <td>0.612783</td>\n",
       "      <td>-0.778394</td>\n",
       "      <td>-0.501113</td>\n",
       "      <td>-0.676212</td>\n",
       "      <td>-1.782262</td>\n",
       "      <td>-2.455907</td>\n",
       "      <td>-1.018984</td>\n",
       "      <td>-1.180690</td>\n",
       "      <td>-1.137868</td>\n",
       "      <td>1.044891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.064931</td>\n",
       "      <td>0.414339</td>\n",
       "      <td>0.791757</td>\n",
       "      <td>-0.944765</td>\n",
       "      <td>0.193523</td>\n",
       "      <td>-1.841067</td>\n",
       "      <td>-1.726388</td>\n",
       "      <td>-0.189720</td>\n",
       "      <td>0.541334</td>\n",
       "      <td>-0.173921</td>\n",
       "      <td>0.150942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.290611</td>\n",
       "      <td>0.315117</td>\n",
       "      <td>-1.356871</td>\n",
       "      <td>-1.063073</td>\n",
       "      <td>-0.172682</td>\n",
       "      <td>-0.841385</td>\n",
       "      <td>0.132710</td>\n",
       "      <td>-0.330160</td>\n",
       "      <td>-0.385910</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>-0.743008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.646153</td>\n",
       "      <td>-0.081770</td>\n",
       "      <td>-0.613115</td>\n",
       "      <td>1.066458</td>\n",
       "      <td>0.330849</td>\n",
       "      <td>1.157980</td>\n",
       "      <td>0.815164</td>\n",
       "      <td>0.990645</td>\n",
       "      <td>-0.518373</td>\n",
       "      <td>0.965289</td>\n",
       "      <td>-0.580471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.379435</td>\n",
       "      <td>0.543838</td>\n",
       "      <td>2.259390</td>\n",
       "      <td>0.147747</td>\n",
       "      <td>0.863956</td>\n",
       "      <td>1.097558</td>\n",
       "      <td>1.997131</td>\n",
       "      <td>1.004955</td>\n",
       "      <td>-0.612079</td>\n",
       "      <td>-0.743008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.013043</td>\n",
       "      <td>-0.180992</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>-1.003919</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>-1.723457</td>\n",
       "      <td>-2.573572</td>\n",
       "      <td>-0.544164</td>\n",
       "      <td>0.673797</td>\n",
       "      <td>1.228183</td>\n",
       "      <td>-0.092863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.712779</td>\n",
       "      <td>-0.677101</td>\n",
       "      <td>0.543838</td>\n",
       "      <td>-0.944765</td>\n",
       "      <td>-0.630437</td>\n",
       "      <td>-0.018117</td>\n",
       "      <td>-0.667408</td>\n",
       "      <td>-1.112611</td>\n",
       "      <td>-1.114458</td>\n",
       "      <td>0.965289</td>\n",
       "      <td>1.938840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.368585</td>\n",
       "      <td>-0.478657</td>\n",
       "      <td>-0.695755</td>\n",
       "      <td>0.307320</td>\n",
       "      <td>-0.172682</td>\n",
       "      <td>-1.135409</td>\n",
       "      <td>-0.714474</td>\n",
       "      <td>0.278413</td>\n",
       "      <td>1.667272</td>\n",
       "      <td>1.052920</td>\n",
       "      <td>-0.174131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.842641</td>\n",
       "      <td>0.811227</td>\n",
       "      <td>-0.530476</td>\n",
       "      <td>-0.018025</td>\n",
       "      <td>-0.813539</td>\n",
       "      <td>0.275907</td>\n",
       "      <td>-0.149685</td>\n",
       "      <td>-0.724729</td>\n",
       "      <td>1.203650</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>0.882355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       -0.064931         -0.577879     0.295920        1.736866   0.239298   \n",
       "1       -0.301959         -0.875545     0.791757        0.888997  -0.035355   \n",
       "2        0.409125         -0.379435    -0.365197       -0.668715  -0.447335   \n",
       "3       -1.250071         -1.073988     0.048001       -0.905330  -0.035355   \n",
       "4       -0.183445         -0.577879    -0.034638       -1.023637  -0.447335   \n",
       "5        0.883181         -1.073988     1.039676       -1.082790  -0.447335   \n",
       "6        0.764667          0.612783    -0.778394       -0.501113  -0.676212   \n",
       "7       -0.064931          0.414339     0.791757       -0.944765   0.193523   \n",
       "8        0.290611          0.315117    -1.356871       -1.063073  -0.172682   \n",
       "9        0.646153         -0.081770    -0.613115        1.066458   0.330849   \n",
       "10       0.409125         -0.379435     0.543838        2.259390   0.147747   \n",
       "11      -1.013043         -0.180992     0.048001       -1.003919   0.010421   \n",
       "12       1.712779         -0.677101     0.543838       -0.944765  -0.630437   \n",
       "13      -1.368585         -0.478657    -0.695755        0.307320  -0.172682   \n",
       "14      -1.842641          0.811227    -0.530476       -0.018025  -0.813539   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0              1.922443              0.932828  1.779784  1.402345   3.156077   \n",
       "1              1.040370              0.368039  1.167867  2.197125   2.455025   \n",
       "2             -1.076604             -0.502678  0.027628  1.137419   1.666341   \n",
       "3              3.568979              0.744565 -1.229644  1.269882   3.594234   \n",
       "4              0.040688             -1.232197 -1.152737 -0.584605   2.367393   \n",
       "5              1.628419              0.203309 -0.925358 -1.114458  -0.699710   \n",
       "6             -1.782262             -2.455907 -1.018984 -1.180690  -1.137868   \n",
       "7             -1.841067             -1.726388 -0.189720  0.541334  -0.173921   \n",
       "8             -0.841385              0.132710 -0.330160 -0.385910  -0.787342   \n",
       "9              1.157980              0.815164  0.990645 -0.518373   0.965289   \n",
       "10             0.863956              1.097558  1.997131  1.004955  -0.612079   \n",
       "11            -1.723457             -2.573572 -0.544164  0.673797   1.228183   \n",
       "12            -0.018117             -0.667408 -1.112611 -1.114458   0.965289   \n",
       "13            -1.135409             -0.714474  0.278413  1.667272   1.052920   \n",
       "14             0.275907             -0.149685 -0.724729  1.203650  -0.787342   \n",
       "\n",
       "     alcohol  \n",
       "0  -0.986812  \n",
       "1  -0.092863  \n",
       "2  -0.336667  \n",
       "3   1.044891  \n",
       "4   0.719818  \n",
       "5   0.150942  \n",
       "6   1.044891  \n",
       "7   0.150942  \n",
       "8  -0.743008  \n",
       "9  -0.580471  \n",
       "10 -0.743008  \n",
       "11 -0.092863  \n",
       "12  1.938840  \n",
       "13 -0.174131  \n",
       "14  0.882355  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tn_X,tn_Y,tt_X,tt_Y = preprocessing(data)\n",
    "X, y,tt_X,tt_Y = preprocessing(data)\n",
    "X = X.reset_index(drop=True)\n",
    "X.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.ix[0,0]\n",
    "X = X.as_matrix() # change type \"DataFrame\" (of Pandas) to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06493106, -0.57787912,  0.29591974, ...,  1.40234528,\n",
       "         3.15607678, -0.9868119 ],\n",
       "       [-0.30195909, -0.87554465,  0.79175698, ...,  2.19712525,\n",
       "         2.45502457, -0.09286267],\n",
       "       [ 0.40912499, -0.37943543, -0.36519658, ...,  1.13741862,\n",
       "         1.66634084, -0.33666701],\n",
       "       ..., \n",
       "       [ 0.40912499, -0.28021359,  0.46119882, ..., -1.44561627,\n",
       "        -0.17392121, -1.23061624],\n",
       "       [-0.89452915, -0.23060267,  0.87439652, ...,  0.34263866,\n",
       "         0.43949948, -0.82427568],\n",
       "       [ 1.59426511, -0.57787912,  0.2132802 , ..., -1.18068962,\n",
       "        -0.96260494, -0.01159456]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to predict an output (0 or 1)\n",
    "def predict(model, x):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Forward propagation\n",
    "    z1 = x.dot(W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = a1.dot(W2) + b2 # 200 x 2 -> (200 x 3) * (3 x 2)\n",
    "    a2 = sigmoid(z2) # 200 x 2\n",
    "    return np.argmax(a2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Forward propagation\n",
    "    z1 = X.dot(W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    corect_probs = np.square(a2 - X) * (1/2)\n",
    "    data_loss = np.sum(corect_probs)\n",
    "    return (1.0/num_examples) * data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot a decision boundary.\n",
    "# If you don't fully understand this function don't worry, it just generates the contour plot below.\n",
    "def plot_decision_boundary(pred_func):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 11)\n"
     ]
    }
   ],
   "source": [
    "num_examples = len(X)\n",
    "nn_input_dim = 11\n",
    "nn_output_dim = 11\n",
    "epsilon = 0.01 #GD update\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):                                        \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(nn_hdim, num_passes=1000, print_loss=False):\n",
    "    np.random.seed() # X is 200 x 2\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim) # 2 x 3\n",
    "    b1 = np.zeros((1, nn_hdim)) # 1 x 3\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim) # 3 x 2\n",
    "    b2 = np.zeros((1, nn_output_dim)) # 1 x 2\n",
    "    \n",
    "    model = {}\n",
    "    \n",
    "    # Gradient Descent in batch\n",
    "    for i in range(0, num_passes):\n",
    "        \n",
    "        # Forward propagation\n",
    "        z1 = X.dot(W1) + b1 #200 x 3 -> (200 x 2) dot (2 x 3)\n",
    "        a1 = sigmoid(z1) # 200 x 3\n",
    "        z2 = a1.dot(W2) + b2 # 200 x 2 -> (200 x 3) * (3 x 2)\n",
    "        a2 = sigmoid(z2) # 200 x 2\n",
    "        # Backpropagation\n",
    "        delta2 = (a2 * (1 - a2)) * (a2 - X) # 200 x 2 -> (200 x 2) * (200 x 2) \n",
    "        dW2 = (a1.T).dot(delta2) # 3 x 2 -> (3 x 200) dot (200 x 2)\n",
    "        db2 = np.sum(delta2, axis=0, keepdims=True) # ? x ?\n",
    "        delta1 = (a1 * (1 - a1)) * (delta2.dot(W2.T)) # 200 x 3 -> (200 x 3) * ((200 x 2) dot (2 x 3))\n",
    "        dW1 = (X.T).dot(delta1) # 2 x 3 -> (2 x 200) dot (200 x 3)\n",
    "        db1 = np.sum(delta1, axis=0) # ? x ?\n",
    "        # Gradient descent parameter update\n",
    "        W1 += -epsilon * dW1\n",
    "        b1 += -epsilon * db1\n",
    "        W2 += -epsilon * dW2\n",
    "        b2 += -epsilon * db2\n",
    "        # Assign new parameters to the model\n",
    "        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "        if print_loss and i % 100 == 0:\n",
    "          print( \"Loss after iteration %i: %f\" %(i, calculate_loss(model)) )\n",
    "    return model, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 5.497466\n",
      "Loss after iteration 100: 5.046233\n",
      "Loss after iteration 200: 5.044744\n",
      "Loss after iteration 300: 4.863730\n",
      "Loss after iteration 400: 4.824587\n",
      "Loss after iteration 500: 4.618550\n",
      "Loss after iteration 600: 4.612336\n",
      "Loss after iteration 700: 4.608733\n",
      "Loss after iteration 800: 4.614546\n",
      "Loss after iteration 900: 4.612149\n"
     ]
    }
   ],
   "source": [
    "# Build a model with a 3-dimensional hidden layer\n",
    "model, a2 = build_model(3, print_loss=True)\n",
    " \n",
    "# Plot the decision boundary -> no use for autoencoder\n",
    "# plot_decision_boundary(lambda x: predict(model, x))\n",
    "# plt.title(\"Decision Boundary for hidden layer size 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.02518239e-05,   7.41208343e-07,   4.57917354e-05, ...,\n",
       "          6.58991547e-07,   1.14225391e-05,   4.86847260e-06],\n",
       "       [  1.28415797e-05,   1.12246032e-06,   4.89743659e-05, ...,\n",
       "          1.13438960e-06,   1.76944283e-05,   3.66848270e-05],\n",
       "       [  2.41881270e-05,   2.69853590e-06,   5.07234044e-06, ...,\n",
       "          1.84428775e-06,   6.16602917e-06,   3.02437919e-04],\n",
       "       ..., \n",
       "       [  8.23390164e-05,   1.22869037e-05,   1.81768724e-04, ...,\n",
       "          5.56745751e-06,   2.47804315e-05,   1.50759773e-05],\n",
       "       [  9.71943089e-06,   6.98911191e-07,   3.59956737e-05, ...,\n",
       "          6.36540577e-07,   1.05622604e-05,   6.53406302e-06],\n",
       "       [  6.48902956e-05,   1.29289017e-05,   1.93013095e-05, ...,\n",
       "          1.05927204e-05,   2.92562272e-05,   1.84367013e-02]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06493106, -0.57787912,  0.29591974, ...,  1.40234528,\n",
       "         3.15607678, -0.9868119 ],\n",
       "       [-0.30195909, -0.87554465,  0.79175698, ...,  2.19712525,\n",
       "         2.45502457, -0.09286267],\n",
       "       [ 0.40912499, -0.37943543, -0.36519658, ...,  1.13741862,\n",
       "         1.66634084, -0.33666701],\n",
       "       ..., \n",
       "       [ 0.40912499, -0.28021359,  0.46119882, ..., -1.44561627,\n",
       "        -0.17392121, -1.23061624],\n",
       "       [-0.89452915, -0.23060267,  0.87439652, ...,  0.34263866,\n",
       "         0.43949948, -0.82427568],\n",
       "       [ 1.59426511, -0.57787912,  0.2132802 , ..., -1.18068962,\n",
       "        -0.96260494, -0.01159456]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.square(a2 - X) * (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
